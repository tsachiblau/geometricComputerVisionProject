#!/usr/bin/env python
"""
This is the main program to run Mindboggle (https://mindboggle.info).

Mindboggle is an open source brain anatomy/morphometry platform
that takes in preprocessed T1-weighted MRI data and outputs volume,
surface, and tabular data containing label, feature,
and shape information for further analysis.

Mindboggle can be run on the command line as "mindboggle" and can be
installed as a cross-platform virtual machine for convenience and
reproducibility of results. The software runs on Linux and is written
in Python 3 and Python-wrapped C++ code called within a modular Nipype
pipeline framework (https://www.nipy.org/nipype/) to promote a modular,
flexible design that captures provenance information (this file).

We have tested the software most extensively for Python 3.5 on Ubuntu 14.04.

For help in using Mindboggle ::

    - Online `documentation <https://mindboggle.info>`_
    - README file
    - Help on the command line::

        $ mindboggle --help

Authors:
    - Arno Klein, 2010-2019  (arno@childmind.org)  https://binarybottle.com
    - Satrajit S. Ghosh, 2013  (satra@mit.edu)  https://www.mit.edu/~satra/
    - Each file lists Mindboggle team members who contributed to its content.

Copyright 2010-2019,  Mindboggle team (https://mindboggle.info), Apache v2.0 License

"""

import os
import argparse
# ----------------------------------------------------------------------------
# Nipype libraries
# ----------------------------------------------------------------------------
from nipype import config, logging
from nipype.interfaces.ants import ApplyTransforms
from nipype.interfaces.io import DataGrabber, DataSink
from nipype.interfaces.utility import Function as Fn
from nipype.interfaces.utility import IdentityInterface
from nipype.pipeline.engine import Workflow, Node
# ----------------------------------------------------------------------------
# Mindboggle libraries
# ----------------------------------------------------------------------------
from mindboggle.data.data import fetch_file_path
from mindboggle.features.folds import find_depth_threshold, extract_folds
from mindboggle.features.fundi import extract_fundi
from mindboggle.features.sulci import extract_sulci
from mindboggle.guts.mesh import rescale_by_neighborhood
from mindboggle.guts.relabel import relabel_surface, relabel_volume, \
    keep_volume_labels, remove_volume_labels, overwrite_volume_labels
from mindboggle.guts.segment import segment_by_region, \
    combine_2labels_in_2volumes
from mindboggle.guts.utilities import list_strings
from mindboggle.mio.convert_volumes import convert2nii
from mindboggle.mio.fetch_data import fetch_ants_data
from mindboggle.mio.labels import DKTprotocol
from mindboggle.mio.tables import write_shape_stats, write_vertex_measures, \
    explode_table
from mindboggle.mio.vtks import read_vtk, apply_affine_transforms, \
    freesurfer_surface_to_vtk, freesurfer_curvature_to_vtk, \
    freesurfer_annot_to_vtk, explode_scalars
from mindboggle.shapes.laplace_beltrami import spectrum_per_label
from mindboggle.shapes.surface_shapes import area, curvature, travel_depth, \
    geodesic_depth
from mindboggle.shapes.volume_shapes import thickinthehead, \
    volume_per_brain_region
from mindboggle.shapes.zernike.zernike import zernike_moments_per_label
from mindboggle.thirdparty.ants import PropagateLabelsThroughMask

from mindboggle.version import __version__ as mbversion
mindboggle_version = 'mindboggle version {0}'.format(mbversion)

# ============================================================================
#
#   Command-line arguments
#
# ============================================================================
parser = argparse.ArgumentParser(description="""
                    The Mindboggle software automates shape analysis of
                    anatomical labels and features extracted from human brain
                    MR image data (https://mindboggle.info).  Example:
                    mindboggle /home/jovyan/work/freesurfer_subjects/arno
                    --ants /home/jovyan/work/ants_subjects/arno/antsBrainSegmentation.nii.gz""",
                                 formatter_class = lambda prog:
                                 argparse.HelpFormatter(prog,
                                                        max_help_position=40))

rec_args = parser.add_argument_group('recommended arguments')
out_args = parser.add_argument_group('modify outputs')
adv_args = parser.add_argument_group('advanced settings')

# "positional arguments":
parser.add_argument("DATA", help=("path to directory of a person's brain "
                                  "data, usually generated by the FreeSurfer "
                                  "software"))
# "optional arguments":
parser.add_argument("--version", help="show mindboggle version number",
                    action='version',
                    version='%(prog)s {}'.format(mbversion))
parser.add_argument("-c", "--cpus",
                    help='number of processors to use (1)',
                    type=int, default=1, metavar='INT')

rec_args.add_argument("--ants",
                      help=("full path to antsBrainSegmentation.nii.gz "
                            "brain segmentation file generated by the "
                            "antsCorticalThickness.sh command"),
                      metavar='STR')

out_args.add_argument("--out",
                      help='output folder (if not $HOME/mindboggled)',
                      default=os.path.join(os.environ['HOME'],
                                           'mindboggled'), metavar='STR')
out_args.add_argument("--working",
                      help="working folder (if not in output folder)",
                      metavar='STR')
out_args.add_argument("--roygbiv", action='store_true',
                      help='prepare data for visualization with ROYGBIV')
out_args.add_argument("--no_volumes", action='store_true',
                      help="no volume labels, features, or shape tables")
out_args.add_argument("--no_surfaces", action='store_true',
                      help="no surface labels, features, or shape tables")
out_args.add_argument("--no_labels", action='store_true',
                      help="no surface or volume labels")
out_args.add_argument("--no_shapes", action='store_true',
                      help="no surface or volume shape measures")
out_args.add_argument("--no_sulci", action='store_true',
                      help="no sulci from labeled folds")
out_args.add_argument("--no_points", action='store_true',
                      help="no table of per-vertex surface shape measures")
out_args.add_argument("--no_moments", action='store_true',
                      help="no Zernike moments per surface label or sulcus")
out_args.add_argument("--no_spectra", action='store_true',
                      help="no Laplace-Beltrami per surface label or sulcus")

adv_args.add_argument("--thickinthehead", action='store_true',
                      help="volume-based cortical label thicknesses")
adv_args.add_argument("--fundi", action='store_true',
                      help="extract, measure fundi (under evaluation, SLOW)")
adv_args.add_argument("--moments",
                      help="reset order of Zernike moments (10)",
                      default=10, type=int, metavar='INT')
adv_args.add_argument("--spectra",
                      help="reset number of Laplace-Beltrami eigenvalues (10)",
                      default=10, type=int, metavar='INT')
adv_args.add_argument("--my_atlas",
                      help=("new atlas, same labels, in MNI space "
                            "(with corresponding template if --ants is set)"),
                      metavar='STR')
adv_args.add_argument("--my_atlases",
                      help=("extra atlas(es) in MNI space with label "
                            "numbers from return_numbers_names_colors()"),
                      nargs='+', metavar='')
adv_args.add_argument("--my_graywhite",
                      help=("new gray/white matter file (ex: edited "
                            "Mindboggle output); still call "
                            "--ants for transforms"),
                      metavar='STR')
adv_args.add_argument("--volume_labels",
                      help=(argparse.SUPPRESS),
                      choices=['wmparc', 'aparc+aseg'],
                      default='wmparc', metavar='STR')
adv_args.add_argument("--surface_labels",
                      help=(argparse.SUPPRESS),
                      choices=['freesurfer', 'manual'],
                      default='freesurfer', metavar='STR')
adv_args.add_argument("--my_transform",
                      help=("different ITK affine transform to MNI space (if "
                            " different template used to get --ants output)"),
                      metavar='STR')
adv_args.add_argument("--graph",
                      help='plot workflow: "hier", "exec" (need graphviz)',
                      choices=['hier', 'flat', 'exec'], metavar='STR')
adv_args.add_argument("--plugin", dest="plugin",
                      default='Linear',
                      help="nipype plugin (see nipype documentation)")
adv_args.add_argument("--plugin_args", dest="plugin_args",
                      help="plugin arguments (see nipype documentation)")
adv_args.add_argument("--prov", action='store_true',
                      help="Capture provenance")
args = parser.parse_args()

# ----------------------------------------------------------------------------
# Input arguments:
# ----------------------------------------------------------------------------
DATA = args.DATA
if not os.path.isdir(DATA):
    raise IOError("Please provide correct path to DATA.")
subject = os.path.basename(DATA)
subjects_dir = os.path.dirname(DATA)
if not subjects_dir:
    if os.environ['SUBJECTS_DIR']:
        subjects_dir = os.environ['SUBJECTS_DIR']
    else:
        raise IOError("Please provide path to DATA or set"
                      " $SUBJECTS_DIR variable.")
if args.my_atlas:
    my_atlas = args.my_atlas
else:
    my_atlas = None
if args.my_graywhite:
    my_graywhite = args.my_graywhite
else:
    my_graywhite = None
if args.my_transform:
    my_transform = args.my_transform
else:
    my_transform = None
use_FS_inputs = True
do_input_vtk = False  # Load VTK surfaces directly (not FreeSurfer surfaces)
do_input_fs_labels = False  # Load nifti (not FreeSurfer mgh file)

# ----------------------------------------------------------------------------
# Output arguments:
# ----------------------------------------------------------------------------
save_all = True  # If False, only save tables
volume_labels = args.volume_labels
surface_labels = args.surface_labels
if args.ants:
    ants_seg = args.ants
    use_ants = True
else:
    use_ants = False
if args.no_labels:
    do_label = False
else:
    do_label = True
if args.no_shapes:
    do_shapes = False
else:
    do_shapes = True

# FreeSurfer shapes:
if do_shapes and use_FS_inputs:
    do_freesurfer_thickness = True
    do_freesurfer_curvature = True
    do_freesurfer_sulc = True
else:
    do_freesurfer_thickness = False  # Include FreeSurfer's thickness measure
    do_freesurfer_curvature = False  # Include FreeSurfer's curvature (curv)
    do_freesurfer_sulc = False  # Include FreeSurfer's convexity (sulc)

# More on/off settings:
save_folds = True
if args.no_sulci:
    do_sulci = False
    do_fundi = False
else:
    do_sulci = True
    do_label = True
    if args.fundi:
        do_fundi = True
    else:
        do_fundi = False
if args.no_points:
    do_points = False
else:
    do_points = True
if args.roygbiv:
    do_points = True
if do_points:
    do_label = True

if args.thickinthehead:
    do_thickinthehead = True
else:
    do_thickinthehead = False

# Set Laplace-Beltrami spectra:
if args.no_spectra:
    do_spectra = False
else:
    do_spectra = True
if do_spectra:
    spectra = args.spectra
    if spectra <= 0:
        raise IOError("spectra needs to be greater than zero.")

# Set Zernike moments:
if args.no_moments:
    do_moments = False
else:
    do_moments = True
if do_moments:
    moments = args.moments
    if moments <= 0:
        raise IOError("moments needs to be greater than zero.")

# Extra labeling atlases in MNI space:
atlases = args.my_atlases
add_atlas_names = []
if atlases:
    if isinstance(atlases, str):
        atlases = [atlases]
    for add_atlas in atlases:
        add_atlas_names.append(os.path.basename(add_atlas).split('.')[0])

# ============================================================================
#
#   Hidden arguments: paths, labels and template data
#
# ============================================================================
ccode_path = os.environ['vtk_cpp_tools']  # Mindboggle C++ code directory
overwrite_cerebrum_with_cerebellum = True
fill_noncortex_with_ants_labels = False
do_surfaces_in_mni = True
background_value = -1
# ----------------------------------------------------------------------------
# Output and working directories:
# ----------------------------------------------------------------------------
# hashes = cache_hashes()
if args.working:
    working = os.path.join(args.working, subject)
else:
    working = os.path.join(args.out, 'working', subject)
if not os.path.isdir(args.out):
    print("Create missing output directory: {0}".format(args.out))
    os.makedirs(args.out)
if not os.path.isdir(working):
    print("Create missing working directory: {0}".format(working))
    os.makedirs(working)
# ----------------------------------------------------------------------------
# Labeling protocol information and volume atlases:
# ----------------------------------------------------------------------------
dkt = DKTprotocol()
atlas_volume = 'OASIS-TRT-20_jointfusion_DKT31_CMA_labels_in_MNI152_v2.nii.gz'
atropos_to_MNI152_affine = 'OASIS-30_Atropos_template_to_MNI152_affine.txt'
# ----------------------------------------------------------------------------
# Surface atlas labels:
# - 'manual': manual edits
# - FUTURE: <'adjusted': manual edits after automated alignment to fundi>
# ----------------------------------------------------------------------------
surface_atlas_type = 'manual'
#modify_surface_labels = False

# ============================================================================
#
#   Basic functions
#
# ============================================================================
#def split_list_pair(List):
#    element1 = List[0]
#    element2 = List[1]
#    return element1, element2


def first_string_containing_substring(substring, List):
    first_matching_string = [x for x in List if substring in x][0]
    return first_matching_string

# Ensure provenance configuration is inherited by workflow
if args.prov:
    config.enable_provenance()

# ============================================================================
#
#   Initialize workflow inputs and outputs
#
# ============================================================================
mbFlow = Workflow(name='Mindboggle')
mbFlow.base_dir = working

# ----------------------------------------------------------------------------
# Iterate inputs over hemispheres and atlases
# (surfaces are assumed to take the form: lh.pial or lh.pial.vtk)
# ----------------------------------------------------------------------------
if add_atlas_names:
    InputVolumeAtlases = Node(name='Input_volume_atlases',
                           interface=IdentityInterface(fields=['atlas']))
    InputVolumeAtlases.iterables = ('atlas', add_atlas_names)
InputHemis = Node(name='Input_hemispheres',
                  interface=IdentityInterface(fields=['hemi']))
hemis = ['lh', 'rh']
InputHemis.iterables = ('hemi', hemis)
# ----------------------------------------------------------------------------
# Outputs and name substitutions
# ----------------------------------------------------------------------------
Sink = Node(DataSink(), name='Results')
Sink.inputs.base_directory = args.out
Sink.inputs.container = subject

if my_graywhite:
    seg_in = os.path.basename(my_graywhite)
else:
    seg_in = 'combined_segmentations.nii.gz'
mgz = volume_labels + '.mgz.nii.gz'
ants_str = 'ants_labels.nii.gz'
fs_filled_fs = '{0}_to_{0}_through_{0}_to_{0}_through_{0}'.format(mgz)
fs_filled = '{0}_to_{0}_through_{1}_to_{0}_through_{1}'.format(mgz, seg_in)
ants_filled_ants = '{0}_to_{1}_to_{1}_through_{0}'.format(mgz, ants_str)


ants_filled = '{0}_to_{1}_to_{1}_through_{2}'.format(mgz, ants_str, seg_in)


fs_filled_fs_rename = 'freesurfer_' + volume_labels + \
                      '_labels_in_freesurfer_graywhite.nii.gz'
fs_filled_rename = 'freesurfer_' + volume_labels + \
                   '_labels_in_hybrid_graywhite.nii.gz'
ants_filled_ants_rename = 'ants_labels_in_ants_graywhite.nii.gz'
ants_filled_rename = 'ants_labels_in_hybrid_graywhite.nii.gz'

Sink.inputs.substitutions = [ ('lh.', ''), ('rh.', ''),
    ('_hemi_lh', 'left_cortical_surface'),
    ('_hemi_rh', 'right_cortical_surface'),
    ('pial.', ''),
    ('thickness.vtk', 'freesurfer_thickness.vtk'),
    ('curv.vtk', 'freesurfer_curvature.vtk'),
    ('sulc.vtk', 'freesurfer_sulc.vtk'),
    ('relabeled_aparc.vtk', 'freesurfer_cortex_labels.vtk'),
    (fs_filled_fs, fs_filled_fs_rename),
    (fs_filled, fs_filled_rename),
    (ants_filled_ants, ants_filled_ants_rename),
    (ants_filled, ants_filled_rename),
    ('segment_per_region.vtk', 'fundus_per_sulcus.vtk')]
# Substitutions for additional atlas names:
Sink.inputs.regexp_substitutions = [
    (r'/_atlas_(.*)/ants_added_atlas_labels.nii.gz', r'/\1_labels.nii.gz'),
    (r'/_atlas_(.*)/volume_for_each_added_label.csv',
     r'/volume_for_each_\1_label.csv'),
    (r'/affine_(.*).vtk', r'/cortex_in_MNI152_space.vtk')]

# ----------------------------------------------------------------------------
# Affine transform from Atropos template to MNI152 space:
# ----------------------------------------------------------------------------
if my_transform:
    affine_template2mni = my_transform
else:
    affine_template2mni = fetch_file_path(atropos_to_MNI152_affine)

# ----------------------------------------------------------------------------
# ANTs data:
# ----------------------------------------------------------------------------
if use_ants:
    FetchAnts = Node(name='Fetch_ants_data',
                     interface=Fn(function=fetch_ants_data,
                                  input_names=['segmented_file',
                                               'use_ants_transforms'],
                                  output_names=['mask',
                                                'segments',
                                                'affine_subject2template',
                                                'warp_subject2template',
                                                'affine_template2subject',
                                                'warp_template2subject']))
    mbFlow.add_nodes([FetchAnts])
    FetchAnts.inputs.segmented_file = ants_seg
    FetchAnts.inputs.use_ants_transforms = True
    # ------------------------------------------------------------------------
    # For transforming volume labels --
    # Make list of ANTs MNI152-to-subject nonlinear transforms
    # to use Apply_ants_transforms:
    #
    # Note regarding Apply_ants_transforms:
    # To warp the subject image to the template, one would call
    # Apply_ants_transforms...-i ${subject} -r ${template}
    #                       -t ${prefix}SubjectToTemplate1Warp.nii.gz
    #                       -t ${prefix}SubjectToTemplate0GenericAffine.mat
    # To warp the template image to the subject, one would call
    # Apply_ants_transforms...-i ${template} -r ${subject}
    #                       -t ${prefix}TemplateToSubject1GenericAffine.mat
    #                       -t ${prefix}TemplateToSubject0Warp.nii.gz
    # ------------------------------------------------------------------------
    ListSubject2mniTransforms = Node(name='List_subject_to_mni_transforms',
                                     interface=Fn(function=list_strings,
                                          input_names=['string1',
                                                       'string2',
                                                       'string3',
                                                       'string4'],
                                          output_names=['string_list']))
    mbFlow.connect(FetchAnts, 'affine_template2subject',
                   ListSubject2mniTransforms, 'string1')
    mbFlow.connect(FetchAnts, 'warp_template2subject',
                   ListSubject2mniTransforms, 'string2')
    ListSubject2mniTransforms.inputs.string3 = affine_template2mni
    ListSubject2mniTransforms.inputs.string4 = ''
    warp_inverse_Booleans = [False, False, True]  # Boolean list
    # ------------------------------------------------------------------------
    # For transforming surface points --
    # Make list of subject-to-MNI affine transforms
    # to use Apply_ants_transformsToPoints:
    #
    # Note regarding Apply_ants_transformsToPoints:
    # Points are transformed in the OPPOSITE direction of images,
    # so you pass the inverse of what is needed to warp the images.
    # Note 2: Don't forget to switch the order of the affine transforms!
    # ------------------------------------------------------------------------
    ListSubject2mniAffineTransforms = Node(
                                name='List_subject_to_mni_affine_transforms',
                                interface=Fn(function=list_strings,
                                             input_names=['string1',
                                                          'string2',
                                                          'string3',
                                                          'string4'],
                                             output_names=['string_list']))
    mbFlow.connect(FetchAnts, 'affine_subject2template',
                   ListSubject2mniAffineTransforms, 'string1')
    ListSubject2mniAffineTransforms.inputs.string2 = affine_template2mni
    ListSubject2mniAffineTransforms.inputs.string3 = ''
    ListSubject2mniAffineTransforms.inputs.string4 = ''
    inverse_Booleans = [1, 1]  # list of ones/zeros for True/False

# ============================================================================
# ----------------------------------------------------------------------------
#
#   Surface workflows
#
# ----------------------------------------------------------------------------
# ============================================================================
if not args.no_surfaces:
    # ------------------------------------------------------------------------
    # Location and structure of the surface inputs:
    # ------------------------------------------------------------------------
    use_white_surface = False
    if use_white_surface:
        Surf = Node(name='Surfaces',
                    interface=DataGrabber(infields=['subject', 'hemi'],
                                          outfields=['surface_files',
                                                     'white_surface_files'],
                                          sort_filelist=False))
    else:
        Surf = Node(name='Surfaces',
                    interface=DataGrabber(infields=['subject', 'hemi'],
                                          outfields=['surface_files'],
                                          sort_filelist=False))
    Surf.inputs.base_directory = subjects_dir
    Surf.inputs.template = '%s/surf/%s.%s'
    Surf.inputs.template_args['surface_files'] = [['subject', 'hemi', 'pial']]
    if use_white_surface:
        Surf.inputs.template_args['white_surface_files'] = [['subject',
                                                             'hemi', 'white']]
    #Surf.inputs.template_args['sphere_files'] = [['subject','hemi','sphere']]
    if do_freesurfer_thickness:
        Surf.inputs.template_args['freesurfer_thickness_files'] = \
            [['subject', 'hemi', 'thickness']]
    if do_freesurfer_curvature:
        Surf.inputs.template_args['freesurfer_curvature_files'] = \
            [['subject', 'hemi', 'curv']]
    if do_freesurfer_sulc:
        Surf.inputs.template_args['freesurfer_sulc_files'] = \
            [['subject', 'hemi', 'sulc']]

    Surf.inputs.subject = subject
    mbFlow.connect(InputHemis, 'hemi', Surf, 'hemi')
    # ------------------------------------------------------------------------
    # Convert surfaces to VTK:
    # ------------------------------------------------------------------------
    if not do_input_vtk:
        Surf2vtk = Node(name='Surface_to_vtk',
                        interface=Fn(function=freesurfer_surface_to_vtk,
                                     input_names=['surface_file',
                                                  'output_vtk'],
                                     output_names=['output_vtk']))
        mbFlow.connect(Surf, 'surface_files', Surf2vtk, 'surface_file')
        Surf2vtk.inputs.output_vtk = ''
        if use_white_surface:
            ConvertWhiteSurf = Surf2vtk.clone('Gray-white_surface_to_vtk')
            mbFlow.add_nodes([ConvertWhiteSurf])
            mbFlow.connect(Surf, 'white_surface_files',
                           ConvertWhiteSurf, 'surface_file')
    # ------------------------------------------------------------------------
    # Evaluation inputs: location and structure of atlas surfaces:
    # ------------------------------------------------------------------------
    if surface_labels == 'manual' and do_label:
        SurfaceAtlas = Node(name='Surface_atlas',
                            interface=DataGrabber(infields=['subject','hemi'],
                                                  outfields=['atlas_file'],
                                                  sort_filelist=False))
        SurfaceAtlas.inputs.base_directory = subjects_dir
        SurfaceAtlas.inputs.template = '%s/label/%s.labels.DKT31.' +\
                                       surface_atlas_type + '.vtk'
        SurfaceAtlas.inputs.template_args['atlas_file'] = [['subject','hemi']]

        SurfaceAtlas.inputs.subject = subject
        mbFlow.connect(InputHemis, 'hemi', SurfaceAtlas, 'hemi')

    # ========================================================================
    #
    #   Surface labels
    #
    # ========================================================================
    if do_label:
        SurfLabelFlow = Workflow(name='Surface_labels')

        # ====================================================================
        # Initialize labels with FreeSurfer
        # ====================================================================
        if surface_labels == 'freesurfer' and use_FS_inputs:
            # ----------------------------------------------------------------
            # Location and structure of the FreeSurfer label inputs:
            # ----------------------------------------------------------------
            if surface_labels == 'freesurfer':
                Annot = Node(name='Freesurfer_annot',
                             interface=DataGrabber(infields=['subject',
                                                             'hemi'],
                                                   outfields=['annot_files'],
                                                   sort_filelist=False))
                Annot.inputs.base_directory = subjects_dir
                Annot.inputs.template = '%s/label/%s.aparc.annot'
                Annot.inputs.template_args['annot_files'] = [['subject',
                                                              'hemi']]
                Annot.inputs.subject = subject
                mbFlow.connect(InputHemis, 'hemi', Annot, 'hemi')
            # ----------------------------------------------------------------
            # Convert Annot to VTK format:
            # ----------------------------------------------------------------
            Annot2vtk = Node(name='Freesurfer_annot_to_vtk',
                             interface=Fn(function=freesurfer_annot_to_vtk,
                                          input_names=['annot_file',
                                                       'vtk_file'],
                                          output_names=['labels',
                                                        'output_vtk']))
            SurfLabelFlow.add_nodes([Annot2vtk])
            mbFlow.connect(Annot, 'annot_files', SurfLabelFlow,
                           'Freesurfer_annot_to_vtk.annot_file')
            if do_input_vtk:
                mbFlow.connect(Surf, 'surface_files', SurfLabelFlow,
                               'Freesurfer_annot_to_vtk.vtk_file')
            else:
                mbFlow.connect(Surf2vtk, 'output_vtk', SurfLabelFlow,
                               'Freesurfer_annot_to_vtk.vtk_file')
            plug = 'Freesurfer_annot_to_vtk.output_vtk'
            plug1 = Annot2vtk
            plug2 = 'output_vtk'

        # ====================================================================
        # Skip label initialization and process manual (atlas) labels
        # ====================================================================
        elif surface_labels == 'manual':
            ManualSurfLabels = Node(name='Manual_surface_labels',
                                    interface=Fn(function=read_vtk,
                                                 input_names=['input_vtk',
                                                              'return_first',
                                                              'return_array'],
                                                 output_names=['faces',
                                                               'lines',
                                                               'indices',
                                                               'points',
                                                               'npoints',
                                                               'scalars',
                                                               'scalar_names',
                                                               'input_vtk']))
            SurfLabelFlow.add_nodes([ManualSurfLabels])
            mbFlow.connect(SurfaceAtlas, 'atlas_file',
                           SurfLabelFlow, 'Manual_surface_labels.input_vtk')
            ManualSurfLabels.inputs.return_first = 'True'
            ManualSurfLabels.inputs.return_array = 'False'
            plug = 'Manual_surface_labels.input_vtk'
            plug1 = ManualSurfLabels
            plug2 = 'input_vtk'

        # ====================================================================
        # Convert surface label numbers to volume DKT31 label numbers
        # ====================================================================
        ReindexLabels = Node(name='Reindex_labels',
                             interface=Fn(function=relabel_surface,
                                          input_names=['vtk_file',
                                                       'hemi',
                                                       'old_labels',
                                                       'new_labels',
                                                       'erase_remaining',
                                                       'erase_labels',
                                                       'erase_value',
                                                       'output_file'],
                                          output_names=['output_file']))
        SurfLabelFlow.add_nodes([ReindexLabels])
        SurfLabelFlow.connect(plug1, plug2, ReindexLabels, 'vtk_file')
        mbFlow.connect(InputHemis, 'hemi',
                       SurfLabelFlow, 'Reindex_labels.hemi')
        ReindexLabels.inputs.old_labels = dkt.DKT31_numbers
        ReindexLabels.inputs.new_labels = []
        ReindexLabels.inputs.erase_remaining = True
        ReindexLabels.inputs.erase_labels = [0]
        ReindexLabels.inputs.erase_value = background_value
        ReindexLabels.inputs.output_file = ''
        if save_all:
            mbFlow.connect(SurfLabelFlow, 'Reindex_labels.output_file',
                           Sink, 'labels.@surface')

    # ========================================================================
    #
    #   Surface shape measurements
    #
    # ========================================================================
    if do_shapes or do_sulci or do_fundi:

        WholeSurfShapeFlow = Workflow(name='Surface_shapes')

        # --------------------------------------------------------------------
        # Measure surface curvature:
        # --------------------------------------------------------------------
        CurvNode = Node(name='Curvature',
                        interface=Fn(function=curvature,
                             input_names=['command',
                                          'method',
                                          'arguments',
                                          'surface_file',
                                          'verbose'],
                             output_names=['mean_curvature_file',
                                           'gauss_curvature_file',
                                           'max_curvature_file',
                                           'min_curvature_file',
                                           'min_curvature_vector_file']))
        CurvNode.inputs.command = os.path.join(ccode_path,
                                               'curvature',
                                               'CurvatureMain')
        CurvNode.inputs.method = 2
        CurvNode.inputs.arguments = '-n 0.7'
        CurvNode.inputs.verbose = True
        # --------------------------------------------------------------------
        # Measure surface travel depth:
        # --------------------------------------------------------------------
        TravelDepth = Node(name='Travel_depth',
                           interface=Fn(function=travel_depth,
                                        input_names=['command',
                                                     'surface_file',
                                                     'verbose'],
                                        output_names=['depth_file']))
        TravelDepth.inputs.command = os.path.join(ccode_path,
                                                  'travel_depth',
                                                  'TravelDepthMain')
        TravelDepth.inputs.verbose = True
        # ----------------------------------------------------------------
        # Connect nodes:
        # ----------------------------------------------------------------
        WholeSurfShapeFlow.add_nodes([TravelDepth, CurvNode])
        if do_input_vtk:
            mbFlow.connect([(Surf, WholeSurfShapeFlow,
                             [('surface_files','Travel_depth.surface_file'),
                              ('surface_files','Curvature.surface_file')])])
        else:
            mbFlow.connect([(Surf2vtk, WholeSurfShapeFlow,
                               [('output_vtk', 'Travel_depth.surface_file'),
                                ('output_vtk', 'Curvature.surface_file')])])
        if save_all:
            mbFlow.connect([(WholeSurfShapeFlow, Sink,
              [('Travel_depth.depth_file', 'shapes.@travel_depth'),
               ('Curvature.mean_curvature_file', 'shapes.@mean_curvature')])])
        # --------------------------------------------------------------------
        # Rescale surface travel depth for fundus extraction:
        # --------------------------------------------------------------------
        if do_fundi:
            RescaleTravelDepth = Node(name='Rescale_travel_depth',
                                interface=Fn(function=rescale_by_neighborhood,
                                     input_names=['input_vtk',
                                                  'indices',
                                                  'nedges',
                                                  'p',
                                                  'set_max_to_1',
                                                  'save_file',
                                                  'output_filestring',
                                                  'background_value'],
                                     output_names=['rescaled_scalars',
                                                   'rescaled_scalars_file']))
            WholeSurfShapeFlow.add_nodes([RescaleTravelDepth])
            WholeSurfShapeFlow.connect(TravelDepth, 'depth_file',
                                       RescaleTravelDepth, 'input_vtk')
            RescaleTravelDepth.inputs.indices = []
            RescaleTravelDepth.inputs.nedges = 10
            RescaleTravelDepth.inputs.p = 99
            RescaleTravelDepth.inputs.set_max_to_1 = True
            RescaleTravelDepth.inputs.save_file = True
            RescaleTravelDepth.inputs.output_filestring = \
                'travel_depth_rescaled'
            RescaleTravelDepth.inputs.background_value = background_value

        # --------------------------------------------------------------------
        # Only compute these shape measures if saving shape tables:
        # --------------------------------------------------------------------
        if do_shapes:
            # ----------------------------------------------------------------
            # Measure surface geodesic depth:
            # ----------------------------------------------------------------
            GeodesicDepth = Node(name='Geodesic_depth',
                                 interface=Fn(function=geodesic_depth,
                                              input_names=['command',
                                                           'surface_file',
                                                           'verbose'],
                                              output_names=['depth_file']))
            GeodesicDepth.inputs.command = os.path.join(ccode_path,
                                                        'geodesic_depth',
                                                        'GeodesicDepthMain')
            GeodesicDepth.inputs.verbose = True
            # ----------------------------------------------------------------
            # Measure surface area:
            # ----------------------------------------------------------------
            SurfaceArea = Node(name='Surface_area',
                               interface=Fn(function=area,
                                            input_names=['command',
                                                         'surface_file',
                                                         'verbose'],
                                            output_names=['area_file']))
            area_command = os.path.join(ccode_path, 'area', 'PointAreaMain')
            SurfaceArea.inputs.command = area_command
            SurfaceArea.inputs.verbose = True

            # ----------------------------------------------------------------
            # Connect nodes:
            # ----------------------------------------------------------------
            WholeSurfShapeFlow.add_nodes([SurfaceArea, GeodesicDepth])
            if do_input_vtk:
                mbFlow.connect([(Surf, WholeSurfShapeFlow,
                                 [('surface_files','Surface_area.surface_file'),
                                  ('surface_files','Geodesic_depth.surface_file')])])
            else:
                mbFlow.connect([(Surf2vtk, WholeSurfShapeFlow,
                                   [('output_vtk', 'Surface_area.surface_file'),
                                    ('output_vtk', 'Geodesic_depth.surface_file')])])
            if save_all:
                mbFlow.connect([(WholeSurfShapeFlow, Sink,
                  [('Surface_area.area_file', 'shapes.@surface_area'),
                   ('Geodesic_depth.depth_file', 'shapes.@geodesic_depth')])])

        # --------------------------------------------------------------------
        # Convert FreeSurfer surface measures to VTK:
        # --------------------------------------------------------------------
        if do_freesurfer_curvature:
            FScurv2vtk = Node(name='Freesurfer_curv_to_vtk',
                           interface=Fn(function=freesurfer_curvature_to_vtk,
                                        input_names=['surface_file',
                                                     'vtk_file',
                                                     'output_vtk'],
                                        output_names=['output_vtk']))
            WholeSurfShapeFlow.add_nodes([FScurv2vtk])
            mbFlow.connect(Surf, 'freesurfer_curvature_files',
                           WholeSurfShapeFlow, 
                           'Freesurfer_curv_to_vtk.surface_file')
            mbFlow.connect(Surf2vtk, 'output_vtk',
                           WholeSurfShapeFlow, 
                           'Freesurfer_curv_to_vtk.vtk_file')
            FScurv2vtk.inputs.output_vtk = ''
            if save_all:
                mbFlow.connect(WholeSurfShapeFlow, 
                               'Freesurfer_curv_to_vtk.output_vtk',
                               Sink, 'shapes.@freesurfer_curvature')
        if do_freesurfer_sulc:
            FSsulc2vtk = Node(name='Freesurfer_sulc_to_vtk',
                           interface=Fn(function=freesurfer_curvature_to_vtk,
                                        input_names=['surface_file',
                                                     'vtk_file',
                                                     'output_vtk'],
                                        output_names=['output_vtk']))
            WholeSurfShapeFlow.add_nodes([FSsulc2vtk])
            mbFlow.connect(Surf, 'freesurfer_sulc_files',
                           WholeSurfShapeFlow, 
                           'Freesurfer_sulc_to_vtk.surface_file')
            mbFlow.connect(Surf2vtk, 'output_vtk',
                           WholeSurfShapeFlow, 
                           'Freesurfer_sulc_to_vtk.vtk_file')
            FSsulc2vtk.inputs.output_vtk = ''
            if save_all:
                mbFlow.connect(WholeSurfShapeFlow, 
                               'Freesurfer_sulc_to_vtk.output_vtk',
                               Sink, 'shapes.@freesurfer_sulc')
        if do_freesurfer_thickness:
            FSthick2vtk = Node(name='Freesurfer_thickness_to_vtk',
                            interface=Fn(function=freesurfer_curvature_to_vtk,
                                         input_names=['surface_file',
                                                      'vtk_file',
                                                      'output_vtk'],
                                         output_names=['output_vtk']))
            WholeSurfShapeFlow.add_nodes([FSthick2vtk])
            mbFlow.connect(Surf, 'freesurfer_thickness_files',
                           WholeSurfShapeFlow,
                           'Freesurfer_thickness_to_vtk.surface_file')
            mbFlow.connect(Surf2vtk, 'output_vtk',
                           WholeSurfShapeFlow, 
                           'Freesurfer_thickness_to_vtk.vtk_file')
            FSthick2vtk.inputs.output_vtk = ''
            if save_all:
                mbFlow.connect(WholeSurfShapeFlow, 
                               'Freesurfer_thickness_to_vtk.output_vtk',
                               Sink, 'shapes.@freesurfer_thickness')

    # ========================================================================
    #
    #   Surface feature extraction
    #
    # ========================================================================
    if do_sulci or do_fundi:
        SurfFeatureFlow = Workflow(name='Surface_features')

        # ====================================================================
        # Folds and sulci
        #
        # Since folds are defined as deep, connected areas of a surface,
        # and since folds may be connected to each other in ways that differ
        # across brains, there usually does not exist a one-to-one mapping
        # between folds of one brain and those of another.
        # To address the correspondence problem then, we need to find just
        # those portions of the folds that correspond across brains.
        # To accomplish this, Mindboggle segments folds into sulci, which
        # do have a one-to-one correspondence across non-pathological brains.
        # ====================================================================
        if do_sulci or do_fundi:
            # ----------------------------------------------------------------
            # Find depth threshold:
            # ----------------------------------------------------------------
            DepthThreshold = Node(name='Depth_threshold',
                             interface=Fn(function=find_depth_threshold,
                                          input_names=['depth_file',
                                                       'min_vertices',
                                                       'verbose'],
                                          output_names=['depth_threshold',
                                                        'bins',
                                                        'bin_edges']))
            SurfFeatureFlow.add_nodes([DepthThreshold])
            mbFlow.connect(WholeSurfShapeFlow, 'Travel_depth.depth_file',
                           SurfFeatureFlow, 'Depth_threshold.depth_file')
            DepthThreshold.inputs.min_vertices = 10000
            DepthThreshold.inputs.verbose = True
            # ----------------------------------------------------------------
            # Folds:
            # ----------------------------------------------------------------
            FoldsNode = Node(name='Folds',
                             interface=Fn(function=extract_folds,
                                          input_names=['depth_file',
                                                       'depth_threshold',
                                                       'min_fold_size',
                                                       'save_file',
                                                       'output_file',
                                                       'background_value',
                                                       'verbose'],
                                          output_names=['folds',
                                                        'n_folds',
                                                        'folds_file']))
            SurfFeatureFlow.add_nodes([FoldsNode])
            mbFlow.connect(WholeSurfShapeFlow, 'Travel_depth.depth_file',
                           SurfFeatureFlow, 'Folds.depth_file')
            SurfFeatureFlow.connect(DepthThreshold, 'depth_threshold',
                                    FoldsNode, 'depth_threshold')
            FoldsNode.inputs.min_fold_size = 50
            FoldsNode.inputs.save_file = True
            FoldsNode.inputs.output_file = ''
            FoldsNode.inputs.background_value = background_value
            FoldsNode.inputs.verbose = True
            if save_folds and save_all:
               mbFlow.connect(SurfFeatureFlow, 'Folds.folds_file',
                              Sink, 'features.@folds')
            # ----------------------------------------------------------------
            # Sulci:
            # ----------------------------------------------------------------
            SulciNode = Node(name='Sulci',
                             interface=Fn(function=extract_sulci,
                                          input_names=['labels_file',
                                                       'folds_or_file',
                                                       'hemi',
                                                       'min_boundary',
                                                       'sulcus_names',
                                                       'background_value',
                                                       'verbose'],
                                          output_names=['sulci',
                                                        'n_sulci',
                                                        'sulci_file']))
            SurfFeatureFlow.add_nodes([SulciNode])
            mbFlow.connect(SurfLabelFlow, 'Reindex_labels.output_file',
                           SurfFeatureFlow, 'Sulci.labels_file')
            SurfFeatureFlow.connect(FoldsNode, 'folds',
                                    SulciNode, 'folds_or_file')
            mbFlow.connect(InputHemis, 'hemi', SurfFeatureFlow, 'Sulci.hemi')
            SulciNode.inputs.min_boundary = 1
            SulciNode.inputs.sulcus_names = dkt.sulcus_names
            if save_all:
                mbFlow.connect(SurfFeatureFlow, 'Sulci.sulci_file',
                               Sink, 'features.@sulci')
            SulciNode.inputs.background_value = background_value
            SulciNode.inputs.verbose = True

        # ====================================================================
        # Fundi
        # ====================================================================
        if do_fundi:
            # ----------------------------------------------------------------
            # Extract a fundus per fold:
            # ----------------------------------------------------------------
            FundusPerFold = Node(name='Fundus_per_fold',
                                 interface=Fn(function=extract_fundi,
                                      input_names=['folds',
                                                   'curv_file',
                                                   'depth_file',
                                                   'min_separation',
                                                   'erode_ratio',
                                                   'erode_min_size',
                                                   'save_file',
                                                   'output_file',
                                                   'background_value',
                                                   'verbose'],
                                      output_names=['fundus_per_fold',
                                                    'n_fundi_in_folds',
                                                    'fundus_per_fold_file']))
            SurfFeatureFlow.connect(FoldsNode, 'folds', 
                                    FundusPerFold, 'folds')
            mbFlow.connect([(WholeSurfShapeFlow, SurfFeatureFlow,
                           [('Curvature.mean_curvature_file',
                             'Fundus_per_fold.curv_file'),
                            ('Rescale_travel_depth.rescaled_scalars_file',
                             'Fundus_per_fold.depth_file')])])
            FundusPerFold.inputs.min_separation = 10
            FundusPerFold.inputs.erode_ratio = 0.10
            FundusPerFold.inputs.erode_min_size = 10
            FundusPerFold.inputs.save_file = True
            FundusPerFold.inputs.output_file = ''
            FundusPerFold.inputs.background_value = background_value
            FundusPerFold.inputs.verbose = True
            if save_all:
                mbFlow.connect(SurfFeatureFlow,
                               'Fundus_per_fold.fundus_per_fold_file',
                               Sink, 'features.@fundus_per_fold')

            # ----------------------------------------------------------------
            # Segment a fundus per sulcus:
            # ----------------------------------------------------------------
            FundusPerSulcus = Node(name='Fundus_per_sulcus',
                               interface=Fn(function=segment_by_region,
                                    input_names=['data',
                                                 'regions',
                                                 'surface_file',
                                                 'save_file',
                                                 'output_file',
                                                 'background_value',
                                                 'verbose'],
                                    output_names=['segment_per_region',
                                                  'n_segments',
                                                  'segment_per_region_file']))
            # if do_smooth_fundi:
            #     SurfFeatureFlow.connect(SmoothFundi, 'smoothed_skeletons',
            #                             FundusPerSulcus, 'data')
            # else:
            SurfFeatureFlow.connect(FundusPerFold, 'fundus_per_fold',
                                    FundusPerSulcus, 'data')
            SurfFeatureFlow.connect(SulciNode, 'sulci', 
                                    FundusPerSulcus, 'regions')
            mbFlow.connect(WholeSurfShapeFlow,
                           'Curvature.mean_curvature_file',
                           SurfFeatureFlow, 'Fundus_per_sulcus.surface_file')
            FundusPerSulcus.inputs.save_file = True
            FundusPerSulcus.inputs.output_file = ''
            FundusPerSulcus.inputs.background_value = background_value
            FundusPerSulcus.inputs.verbose = True
            if save_all:
                mbFlow.connect(SurfFeatureFlow,
                               'Fundus_per_sulcus.segment_per_region_file',
                               Sink, 'features.@fundus_per_sulcus')

    # ========================================================================
    #
    #   Surface feature shapes
    #
    # ========================================================================
    if do_shapes:
        SurfFeatureShapeFlow = Workflow(name='Surface_feature_shapes')
        # ====================================================================
        # Compute Laplace-Beltrami spectra
        # ====================================================================
        if do_spectra:
            # ----------------------------------------------------------------
            # Measure spectra of labeled regions:
            # ----------------------------------------------------------------
            SpectraLabels = Node(name='Spectra_labels',
                                 interface=Fn(function=spectrum_per_label,
                                              input_names=['vtk_file',
                                                           'spectrum_size',
                                                           'exclude_labels',
                                                           'normalization',
                                                           'area_file',
                                                           'largest_segment',
                                                           'verbose'],
                                              output_names=['spectrum_lists',
                                                            'label_list']))
            SurfFeatureShapeFlow.add_nodes([SpectraLabels])
            mbFlow.connect(SurfLabelFlow, 'Reindex_labels.output_file',
                           SurfFeatureShapeFlow, 'Spectra_labels.vtk_file')
            SpectraLabels.inputs.spectrum_size = spectra
            SpectraLabels.inputs.exclude_labels = [0]
            SpectraLabels.inputs.normalization = "areaindex"
            SpectraLabels.inputs.area_file = ""
            SpectraLabels.inputs.largest_segment = True
            SpectraLabels.inputs.verbose = True
            mbFlow.connect(WholeSurfShapeFlow, 'Surface_area.area_file',
                           SurfFeatureShapeFlow, 'Spectra_labels.area_file')
            # ----------------------------------------------------------------
            # Compute spectra of sulci:
            # ----------------------------------------------------------------
            if do_sulci:
                SpectraSulci = SpectraLabels.clone('Spectra_sulci')
                SurfFeatureShapeFlow.add_nodes([SpectraSulci])
                mbFlow.connect(SurfFeatureFlow, 'Sulci.sulci_file',
                               SurfFeatureShapeFlow, 'Spectra_sulci.vtk_file')
                SpectraSulci.inputs.exclude_labels = [background_value]

        # ====================================================================
        # Compute Zernike moments
        # ====================================================================
        if do_moments:
            # ----------------------------------------------------------------
            # Measure Zernike moments of labeled regions:
            # ----------------------------------------------------------------
            ZernikeLabels = Node(name='Zernike_labels',
                 interface=Fn(function=zernike_moments_per_label,
                              input_names=['vtk_file',
                                           'order',
                                           'exclude_labels',
                                           'scale_input',
                                           'decimate_fraction',
                                           'decimate_smooth',
                                           'verbose'],
                              output_names=['descriptors_lists',
                                            'label_list']))
            SurfFeatureShapeFlow.add_nodes([ZernikeLabels])
            mbFlow.connect(SurfLabelFlow, 'Reindex_labels.output_file',
                           SurfFeatureShapeFlow, 'Zernike_labels.vtk_file')
            ZernikeLabels.inputs.order = moments
            ZernikeLabels.inputs.exclude_labels = [0]
            ZernikeLabels.inputs.scale_input = True
            ZernikeLabels.inputs.decimate_fraction = 0
            ZernikeLabels.inputs.decimate_smooth = 0
            ZernikeLabels.inputs.verbose = True
            # ----------------------------------------------------------------
            # Compute Zernike moments of sulci:
            # ----------------------------------------------------------------
            if do_sulci:
                ZernikeSulci = ZernikeLabels.clone('Zernike_sulci')
                SurfFeatureShapeFlow.add_nodes([ZernikeSulci])
                mbFlow.connect(SurfFeatureFlow, 'Sulci.sulci_file',
                               SurfFeatureShapeFlow, 'Zernike_sulci.vtk_file')
                ZernikeSulci.inputs.exclude_labels = [background_value]

    # ========================================================================
    #
    #   Surface feature shape tables
    #
    # ========================================================================
    if do_shapes:
        # --------------------------------------------------------------------
        # Surface feature shape tables: labels, sulci, fundi:
        #
        # There can be thousands of vertices in a single feature such as a
        # gyrus, sulcus, or fundus, and for per-vertex shape measures,
        # it makes sense to characterize their collective shape as a
        # distribution of shape values. Mindboggle's stats_per_label
        # function generates tables of summary statistical measures for
        # these distributions, and includes the shape measures computed on
        # cortical features as well.
        # --------------------------------------------------------------------
        ShapeTables = Node(name='Shape_tables',
                           interface=Fn(function=write_shape_stats,
                                input_names=['labels_or_file',
                                             'sulci',
                                             'fundi',
                                             'affine_transform_files',
                                             'inverse_booleans',
                                             'transform_format',
                                             'area_file',
                                             'normalize_by_area',
                                             'mean_curvature_file',
                                             'travel_depth_file',
                                             'geodesic_depth_file',
                                             'freesurfer_thickness_file',
                                             'freesurfer_curvature_file',
                                             'freesurfer_sulc_file',
                                             'labels_spectra',
                                             'labels_spectra_IDs',
                                             'sulci_spectra',
                                             'sulci_spectra_IDs',
                                             'labels_zernike',
                                             'labels_zernike_IDs',
                                             'sulci_zernike',
                                             'sulci_zernike_IDs',
                                             'exclude_labels'],
                                output_names=['label_table',
                                              'sulcus_table',
                                              'fundus_table']))
        mbFlow.add_nodes([ShapeTables])
        ShapeTables.inputs.labels_or_file = []
        ShapeTables.inputs.sulci = []
        ShapeTables.inputs.fundi = []
        ShapeTables.inputs.affine_transform_files = None
        ShapeTables.inputs.inverse_booleans = None
        ShapeTables.inputs.transform_format = None
        ShapeTables.inputs.freesurfer_thickness_file = ''
        ShapeTables.inputs.freesurfer_curvature_file = ''
        ShapeTables.inputs.freesurfer_sulc_file = ''
        ShapeTables.inputs.labels_spectra = []
        ShapeTables.inputs.sulci_spectra = []
        ShapeTables.inputs.labels_spectra_IDs = []
        ShapeTables.inputs.sulci_spectra_IDs = []
        ShapeTables.inputs.labels_zernike = []
        ShapeTables.inputs.sulci_zernike = []
        ShapeTables.inputs.labels_zernike_IDs = []
        ShapeTables.inputs.sulci_zernike_IDs = []
        if do_label:
            mbFlow.connect(SurfLabelFlow, 'Reindex_labels.output_file',
                           ShapeTables, 'labels_or_file')
        if do_sulci:
            mbFlow.connect(SurfFeatureFlow, 'Sulci.sulci',
                           ShapeTables, 'sulci')
        if do_fundi:
            mbFlow.connect(SurfFeatureFlow,
                           'Fundus_per_sulcus.segment_per_region',
                           ShapeTables, 'fundi')
        if use_ants:
            mbFlow.connect(ListSubject2mniAffineTransforms, 'string_list',
                           ShapeTables, 'affine_transform_files')
            ShapeTables.inputs.inverse_booleans = inverse_Booleans
            ShapeTables.inputs.transform_format = 'itk'
        ShapeTables.inputs.normalize_by_area = False
        mbFlow.connect([(WholeSurfShapeFlow, ShapeTables,
                   [('Surface_area.area_file', 'area_file'),
                    ('Curvature.mean_curvature_file', 'mean_curvature_file'),
                    ('Travel_depth.depth_file', 'travel_depth_file'),
                    ('Geodesic_depth.depth_file', 'geodesic_depth_file')])])
        if do_freesurfer_thickness:
            mbFlow.connect(WholeSurfShapeFlow, 
                           'Freesurfer_thickness_to_vtk.output_vtk',
                           ShapeTables, 'freesurfer_thickness_file')
        if do_freesurfer_curvature:
            mbFlow.connect(WholeSurfShapeFlow, 
                           'Freesurfer_curv_to_vtk.output_vtk',
                           ShapeTables, 'freesurfer_curvature_file')
        if do_freesurfer_sulc:
            mbFlow.connect(WholeSurfShapeFlow, 
                           'Freesurfer_sulc_to_vtk.output_vtk',
                           ShapeTables, 'freesurfer_sulc_file')

        # Laplace-Beltrami spectra:
        if do_spectra:
            mbFlow.connect(SurfFeatureShapeFlow,
                           'Spectra_labels.spectrum_lists',
                           ShapeTables, 'labels_spectra')
            mbFlow.connect(SurfFeatureShapeFlow, 'Spectra_labels.label_list',
                           ShapeTables, 'labels_spectra_IDs')
            if do_sulci:
                mbFlow.connect(SurfFeatureShapeFlow,
                               'Spectra_sulci.spectrum_lists',
                               ShapeTables, 'sulci_spectra')
                mbFlow.connect(SurfFeatureShapeFlow,
                               'Spectra_sulci.label_list',
                               ShapeTables, 'sulci_spectra_IDs')
            else:
                ShapeTables.inputs.sulci_spectra = []
                ShapeTables.inputs.sulci_spectra_IDs = []

        # Zernike moments:
        if do_moments:
            mbFlow.connect(SurfFeatureShapeFlow,
                           'Zernike_labels.descriptors_lists',
                           ShapeTables, 'labels_zernike')
            mbFlow.connect(SurfFeatureShapeFlow, 'Zernike_labels.label_list',
                           ShapeTables, 'labels_zernike_IDs')
            if do_sulci:
                mbFlow.connect(SurfFeatureShapeFlow,
                               'Zernike_sulci.descriptors_lists',
                               ShapeTables, 'sulci_zernike')
                mbFlow.connect(SurfFeatureShapeFlow,
                               'Zernike_sulci.label_list',
                               ShapeTables, 'sulci_zernike_IDs')
            else:
                ShapeTables.inputs.sulci_zernike = []
                ShapeTables.inputs.sulci_zernike_IDs = []

        ## To avoid error when running Docker container as an executable:
        #ShapeTables.interface._redirect_x = True

        ShapeTables.inputs.exclude_labels = [background_value]
        mbFlow.connect(ShapeTables, 'label_table', Sink, 'tables.@labels')
        if do_sulci:
            mbFlow.connect(ShapeTables, 'sulcus_table', Sink, 'tables.@sulci')
        if do_fundi:
            mbFlow.connect(ShapeTables, 'fundus_table', Sink, 'tables.@fundi')
        # --------------------------------------------------------------------
        # Vertex measures table:
        # --------------------------------------------------------------------
        if do_points:
            VertexTable = Node(name='Vertex_table',
                               interface=Fn(function=write_vertex_measures,
                                    input_names=['output_table',
                                                 'labels_or_file',
                                                 'sulci',
                                                 'fundi',
                                                 'affine_transform_files',
                                                 'inverse_booleans',
                                                 'transform_format',
                                                 'area_file',
                                                 'mean_curvature_file',
                                                 'travel_depth_file',
                                                 'geodesic_depth_file',
                                                 'freesurfer_thickness_file',
                                                 'freesurfer_curvature_file',
                                                 'freesurfer_sulc_file'],
                                    output_names=['output_table']))
            mbFlow.add_nodes([VertexTable])
            VertexTable.inputs.output_table = ''
            VertexTable.inputs.labels_or_file = []
            VertexTable.inputs.sulci = []
            VertexTable.inputs.fundi = []
            VertexTable.inputs.affine_transform_files = None
            VertexTable.inputs.inverse_booleans = None
            VertexTable.inputs.transform_format = None
            VertexTable.inputs.freesurfer_thickness_file = ''
            VertexTable.inputs.freesurfer_curvature_file = ''
            VertexTable.inputs.freesurfer_sulc_file = ''
            if do_label:
                mbFlow.connect(SurfLabelFlow, 'Reindex_labels.output_file',
                               VertexTable, 'labels_or_file')
            if do_sulci:
                mbFlow.connect(SurfFeatureFlow, 'Sulci.sulci',
                               VertexTable, 'sulci')
            if do_fundi:
                mbFlow.connect(SurfFeatureFlow,
                               'Fundus_per_sulcus.segment_per_region',
                               VertexTable, 'fundi')

            if use_ants:
                mbFlow.connect(ListSubject2mniAffineTransforms, 'string_list',
                               VertexTable, 'affine_transform_files')
                VertexTable.inputs.inverse_booleans = inverse_Booleans
                VertexTable.inputs.transform_format = 'itk'
            mbFlow.connect([(WholeSurfShapeFlow, VertexTable,
                               [('Surface_area.area_file','area_file'),
                                ('Travel_depth.depth_file',
                                 'travel_depth_file'),
                                ('Geodesic_depth.depth_file',
                                 'geodesic_depth_file'),
                                ('Curvature.mean_curvature_file',
                                 'mean_curvature_file')])])
            if do_freesurfer_thickness:
                mbFlow.connect(WholeSurfShapeFlow,
                               'Freesurfer_thickness_to_vtk.output_vtk',
                               VertexTable, 'freesurfer_thickness_file')
            if do_freesurfer_curvature:
                mbFlow.connect(WholeSurfShapeFlow,
                               'Freesurfer_curv_to_vtk.output_vtk',
                               VertexTable, 'freesurfer_curvature_file')
            if do_freesurfer_sulc:
                mbFlow.connect(WholeSurfShapeFlow,
                               'Freesurfer_sulc_to_vtk.output_vtk',
                               VertexTable, 'freesurfer_sulc_file')

            ## To avoid error when running Docker container as an executable:
            #VertexTable.interface._redirect_x = True

            mbFlow.connect(VertexTable, 'output_table',
                           Sink, 'tables.@vertices')

        # --------------------------------------------------------------------
        # Apply affine transform to surface coordinates:
        # --------------------------------------------------------------------
        if use_ants and do_surfaces_in_mni:
            TransformPoints = Node(name='Transform_surface_points',
                                interface=Fn(function=apply_affine_transforms,
                                             input_names=['transform_files',
                                                          'inverse_booleans',
                                                          'transform_format',
                                                          'vtk_or_points',
                                                          'vtk_file_stem'],
                                             output_names=['affine_points',
                                                           'output_file']))
            mbFlow.add_nodes([TransformPoints])
            mbFlow.connect(ListSubject2mniAffineTransforms, 'string_list',
                           TransformPoints, 'transform_files')
            mbFlow.connect(TravelDepth, 'depth_file',
                           TransformPoints, 'vtk_or_points')
            TransformPoints.inputs.inverse_booleans = inverse_Booleans
            TransformPoints.inputs.transform_format = 'itk'
            TransformPoints.inputs.vtk_file_stem = 'affine_'
            if save_all:
                mbFlow.connect(TransformPoints, 'output_file',
                               Sink, 'features.@surface_in_MNI152')

        # --------------------------------------------------------------------
        # Surface shape visualization: prepare data for ROYGBIV
        # --------------------------------------------------------------------
        if args.roygbiv:
            # ----------------------------------------------------------------
            # Explode surface shape files by label values:
            # ----------------------------------------------------------------
            ExplodeLabels = Node(name='Explode_Labels',
                                 interface=Fn(function=explode_scalars,
                                     input_names=['input_indices_vtk',
                                                  'input_values_vtk',
                                                  'output_stem',
                                                  'exclude_values',
                                                  'background_value',
                                                  'output_scalar_name',
                                                  'remove_background_faces',
                                                  'reindex',
                                                  'verbose'],
                                     output_names=['output_files']))
            mbFlow.connect(ReindexLabels, 'output_file',
                           ExplodeLabels, 'input_indices_vtk')
            ExplodeLabels.inputs.input_values_vtk = ''
            ExplodeLabels.inputs.output_stem = 'label'
            ExplodeLabels.inputs.exclude_values = [-1]
            ExplodeLabels.inputs.background_value = -1
            ExplodeLabels.inputs.output_scalar_name = 'scalars'
            ExplodeLabels.inputs.remove_background_faces = True
            ExplodeLabels.inputs.reindex = True
            ExplodeLabels.inputs.verbose = True
            if save_all:
                mbFlow.connect(ExplodeLabels, 'output_files',
                               Sink, 'exploded.@labels')

            # ----------------------------------------------------------------
            # Explode surface shape files by sulcus indices:
            # ----------------------------------------------------------------
            if do_sulci:
                ExplodeSulci = ExplodeLabels.clone('Explode_Sulci')
                mbFlow.connect(SurfFeatureFlow, 'Sulci.sulci_file',
                               ExplodeSulci, 'input_indices_vtk')
                ExplodeSulci.inputs.output_stem = 'sulcus'
                if save_all:
                    mbFlow.connect(ExplodeSulci, 'output_files',
                                   Sink, 'exploded.@sulci')

            # ----------------------------------------------------------------
            # Explode surface shape files by fundus indices:
            # ----------------------------------------------------------------
            if do_fundi:
                ExplodeFundi = ExplodeLabels.clone('Explode_Fundi')
                mbFlow.connect(SurfFeatureFlow,
                               'Fundus_per_sulcus.segment_per_region_file',
                               ExplodeFundi, 'input_indices_vtk')
                ExplodeFundi.inputs.output_stem = 'fundus'
                if save_all:
                    mbFlow.connect(ExplodeFundi, 'output_files',
                                   Sink, 'exploded.@fundi')

            # ----------------------------------------------------------------
            # Explode surface shape tables by label values:
            # ----------------------------------------------------------------
            ExplodeLabelTable = Node(name='Explode_Label_Table',
                                interface=Fn(function=explode_table,
                                             input_names=['input_table',
                                                          'column_headers',
                                                          'output_path',
                                                          'output_stem',
                                                          'break_column',
                                                          'verbose'],
                                             output_names=['output_tables']))
            mbFlow.connect(VertexTable, 'output_table',
                           ExplodeLabelTable, 'input_table')
            ExplodeLabelTable.inputs.column_headers = ['travel depth',
                                                'geodesic depth',
                                                'mean curvature',
                                                'freesurfer curvature',
                                                'freesurfer thickness',
                                                'freesurfer convexity (sulc)']
            ExplodeLabelTable.inputs.output_path = None
            ExplodeLabelTable.inputs.output_stem = 'label'
            ExplodeLabelTable.inputs.break_column = 'label ID'
            ExplodeLabelTable.inputs.verbose = True
            if save_all:
                mbFlow.connect(ExplodeLabelTable, 'output_tables',
                               Sink, 'exploded.@label_tables')

            # ----------------------------------------------------------------
            # Explode surface shape tables by sulcus indices:
            # ----------------------------------------------------------------
            if do_sulci:
                ExplodeSulcusTable = ExplodeLabelTable.clone('Explode_Sulcus_Table')
                mbFlow.connect(VertexTable, 'output_table',
                               ExplodeSulcusTable, 'input_table')
                ExplodeSulcusTable.inputs.output_path = None
                ExplodeSulcusTable.inputs.output_stem = 'sulcus'
                ExplodeSulcusTable.inputs.break_column = 'sulcus ID'
                if save_all:
                    mbFlow.connect(ExplodeSulcusTable, 'output_tables',
                                   Sink, 'exploded.@sulcus_tables')

            # ----------------------------------------------------------------
            # Explode surface shape tables by fundus indices:
            # ----------------------------------------------------------------
            if do_fundi:
                ExplodeFundusTable = ExplodeLabels.clone('Explode_Fundus_Table')
                mbFlow.connect(VertexTable, 'output_table',
                               ExplodeFundusTable, 'input_table')
                ExplodeFundusTable.inputs.output_path = None
                ExplodeFundusTable.inputs.output_stem = 'fundus'
                ExplodeFundusTable.inputs.break_column = 'fundus ID'
                if save_all:
                    mbFlow.connect(ExplodeFundusTable, 'output_tables',
                                   Sink, 'exploded.@fundus_tables')

# ============================================================================
# ----------------------------------------------------------------------------
#
#   Volume workflows
#
# ----------------------------------------------------------------------------
# ============================================================================
if do_label and not args.no_volumes:

    # ========================================================================
    #
    #   Location and structure of FreeSurfer volume inputs
    #
    # ========================================================================
    # ------------------------------------------------------------------------
    # Original image (.mgz) for converting from conformal (below):
    # ------------------------------------------------------------------------
    MRImgh = Node(name='MRI_mgh_format',
                  interface=DataGrabber(infields=['subject'],
                                        outfields=['MRI_mgh_format'],
                                        sort_filelist=False))
    MRImgh.inputs.base_directory = subjects_dir
    second_scan = os.path.join(subjects_dir, 'mri/orig/002.mgz')
    if os.path.exists(second_scan):
        raise IOError("Mindboggle can not make use of FreeSurfer "
                      "output with more than one scan: " + second_scan)
    MRImgh.inputs.template = '%s/mri/orig/001.mgz'
    MRImgh.inputs.template_args['MRI_mgh_format'] = [['subject']]
    MRImgh.inputs.subject = subject
    # --------------------------------------------------------------------
    # Convert FreeSurfer mgh conformal file to nifti format:
    # --------------------------------------------------------------------
    mgh2nifti = Node(name='Convert_MRI_to_nifti_format',
                     interface=Fn(function=convert2nii,
                                  input_names=['input_file',
                                               'reference_file',
                                               'output_file',
                                               'interp'],
                                  output_names=['output_file']))
    mbFlow.connect(MRImgh, 'MRI_mgh_format', mgh2nifti, 'input_file')
    mbFlow.connect(MRImgh, 'MRI_mgh_format', mgh2nifti, 'reference_file')
    mgh2nifti.inputs.output_file = ''
    mgh2nifti.inputs.interp = 'continuous'
    # ------------------------------------------------------------------------
    # Use own whole-brain nifti label volume:
    # ------------------------------------------------------------------------
    if do_input_fs_labels:
        labels2nifti = Node(name='Labels_nifti_format',
                            interface=DataGrabber(infields=['subject'],
                                                  outfields=['labels'],
                                                  sort_filelist=False))
        labels2nifti.inputs.base_directory = subjects_dir
        labels2nifti.inputs.template = '%s/mri/' + volume_labels+'.nii.gz'
        labels2nifti.inputs.template_args['labels'] = [['subject']]
        labels2nifti.inputs.subject = subject
    # ------------------------------------------------------------------------
    # Convert FreeSurfer whole-brain label volume to nifti format:
    # ------------------------------------------------------------------------
    else:
        # --------------------------------------------------------------------
        #  label volume:
        # --------------------------------------------------------------------
        labels2mgh = Node(name='Labels_mgh_format',
                          interface=DataGrabber(infields=['subject'],
                                                outfields=['labels'],
                                                sort_filelist=False))
        labels2mgh.inputs.base_directory = subjects_dir
        labels2mgh.inputs.template = '%s/mri/' + volume_labels+'.mgz'
        labels2mgh.inputs.template_args['labels'] = [['subject']]
        labels2mgh.inputs.subject = subject
        # --------------------------------------------------------------------
        # Convert FreeSurfer mgh conformal file to nifti format:
        # --------------------------------------------------------------------
        labelsmgh2nifti = Node(name='Convert_labels_to_nifti_format',
                               interface=Fn(function=convert2nii,
                                            input_names=['input_file',
                                                         'reference_file',
                                                         'output_file',
                                                         'interp'],
                                            output_names=['output_file']))
        mbFlow.connect(labels2mgh, 'labels', labelsmgh2nifti, 'input_file')
        mbFlow.connect(MRImgh, 'MRI_mgh_format',
                       labelsmgh2nifti, 'reference_file')
        labelsmgh2nifti.inputs.output_file = ''
        labelsmgh2nifti.inputs.interp = 'nearest'
        #if save_all:
        #    mbFlow.connect(labelsmgh2nifti, 'output_file',
        #                   Sink, 'labels.@freesurfer')

    # ========================================================================
    #
    #   Volume labels
    #
    # ========================================================================
    VolLabelFlow = Workflow(name='Volume_labels')

    # ------------------------------------------------------------------------
    # Extract FreeSurfer cerebellum labels:
    # ------------------------------------------------------------------------
    FScerebellum = Node(name='Extract_freesurfer_cerebella',
                        interface=Fn(function=keep_volume_labels,
                                     input_names=['input_file',
                                                  'labels_to_keep',
                                                  'output_file',
                                                  'second_file'],
                                     output_names=['output_file']))
    VolLabelFlow.add_nodes([FScerebellum])
    if do_input_fs_labels:
        mbFlow.connect(labels2nifti, 'labels', VolLabelFlow,
                       'Extract_freesurfer_cerebella.input_file')
    else:
        mbFlow.connect(labelsmgh2nifti, 'output_file', VolLabelFlow,
                       'Extract_freesurfer_cerebella.input_file')
    FScerebellum.inputs.labels_to_keep = dkt.cerebellum_numbers
    FScerebellum.inputs.output_file = ''
    FScerebellum.inputs.second_file = ''

    # ========================================================================
    # Combine FreeSurfer and ANTs cerebrum gray/white matter volumes
    # ========================================================================
    if not my_graywhite:
        # --------------------------------------------------------------------
        # Extract FreeSurfer cerebrum labels:
        # --------------------------------------------------------------------
        FScerebrum = Node(name='Extract_freesurfer_cerebra',
                          interface=Fn(function=keep_volume_labels,
                                       input_names=['input_file',
                                                    'labels_to_keep',
                                                    'output_file',
                                                    'second_file'],
                                       output_names=['output_file']))
        VolLabelFlow.add_nodes([FScerebrum])
        if do_input_fs_labels:
            mbFlow.connect(labels2nifti, 'labels', VolLabelFlow,
                           'Extract_freesurfer_cerebra.input_file')
        else:
            mbFlow.connect(labelsmgh2nifti, 'output_file', VolLabelFlow,
                           'Extract_freesurfer_cerebra.input_file')
        labels_to_segment = dkt.cerebrum_cortex_numbers + \
                            dkt.cerebrum_noncortex_numbers + \
                            dkt.brainstem_numbers + \
                            dkt.extra_numbers
        FScerebrum.inputs.labels_to_keep = labels_to_segment
        FScerebrum.inputs.output_file = ''
        FScerebrum.inputs.second_file = ''
        # --------------------------------------------------------------------
        # Convert FreeSurfer cerebrum labels to non/cortex segments:
        # --------------------------------------------------------------------
        FSgraywhite = Node(name='Freesurfer_cerebrum_labels_to_graywhite',
                           interface=Fn(function=relabel_volume,
                                        input_names=['input_file',
                                                     'old_labels',
                                                     'new_labels',
                                                     'output_file'],
                                        output_names=['output_file']))
        VolLabelFlow.add_nodes([FSgraywhite])
        VolLabelFlow.connect(FScerebrum, 'output_file',
                             FSgraywhite, 'input_file')
        FSgraywhite.inputs.old_labels = labels_to_segment
        FSgraywhite.inputs.new_labels = \
            [2 for x in dkt.cerebrum_cortex_numbers] + \
            [3 for x in dkt.cerebrum_noncortex_numbers] + \
            [3 for x in dkt.brainstem_numbers] + \
            [3 for x in dkt.extra_numbers]
        FSgraywhite.inputs.output_file = ''
        # --------------------------------------------------------------------
        # Convert ANTs Atropos-segmented volume to non/cortex segments:
        # --------------------------------------------------------------------
        if use_ants:
            antsGrayWhite = FSgraywhite.clone('Ants_brain_labels_to_graywhite')
            VolLabelFlow.add_nodes([antsGrayWhite])
            mbFlow.connect(FetchAnts, 'segments', VolLabelFlow,
                           'Ants_brain_labels_to_graywhite.input_file')
            antsGrayWhite.inputs.old_labels = [1, 4]
            antsGrayWhite.inputs.new_labels = [0, 3]
            antsGrayWhite.inputs.output_file = ''
            # ----------------------------------------------------------------
            # Combine FreeSurfer and ANTs cerebrum segmentation volumes to
            # obtain a single cortex (2) and noncortex (3) segmentation file.
            #
            # FreeSurfer and ANTs both perform tissue class segmentation of
            # T1-weighted MR brain images into gray and white matter, and
            # other components. The relabel_volume function converts the
            # (wmparc.mgz) labeled file generated by FreeSurfer and the
            # (BrainSegmentation.nii.gz) segmented file generated by the ANTs
            # Atropos function [ref] to binary files of white matter and gray
            # (including deep gray) matter. After visual inspection of the
            # gray/white matter boundaries in hundreds of FreeSurfer- and
            # ANTs-processed brains, we found that ANTs tends to include more
            # cortical gray matter at the periphery of the brain than
            # FreeSurfer, and FreeSurfer tends to include more white matter
            # that extends deep into gyral folds than ANTs, so Mindboggle's
            # combine_2labels_in_2volumes function attempts to remedy their
            # differences by overlaying ANTs cortical gray with FreeSurfer
            # white matter, by taking the union of cortex voxels from the two
            # binary files, the union of the non-cortex voxels from the two
            # binary files, and assigning intersecting cortex and non-cortex
            # voxels as non-cortex.
            # ----------------------------------------------------------------
            JoinGrayWhite = Node(name=
                            'Combine_freesurfer_ants_cerebrum_graywhite',
                            interface=Fn(function=combine_2labels_in_2volumes,
                                         input_names=['file1',
                                                      'file2',
                                                      'label1',
                                                      'label2',
                                                      'output_file'],
                                         output_names=['output_file']))
            VolLabelFlow.add_nodes([JoinGrayWhite])
            VolLabelFlow.connect(FSgraywhite, 'output_file', 
                                 JoinGrayWhite, 'file1')
            JoinGrayWhite.inputs.out_dir = ''
            VolLabelFlow.connect(antsGrayWhite, 'output_file',
                                 JoinGrayWhite, 'file2')
            JoinGrayWhite.inputs.label1 = 3
            JoinGrayWhite.inputs.label2 = 2
            JoinGrayWhite.inputs.output_file = ''
            # ----------------------------------------------------------------
            # Erase cerebrum that overlaps with FreeSurfer cerebellum:
            # ----------------------------------------------------------------
            if overwrite_cerebrum_with_cerebellum:
                RemoveCerebellum = Node(
                    name='Remove_cerebrum_cerebellum_overlap',
                    interface=Fn(function=remove_volume_labels,
                                 input_names=['input_file',
                                              'labels_to_remove',
                                              'output_file',
                                              'second_file'],
                                 output_names=['output_file']))
                VolLabelFlow.add_nodes([RemoveCerebellum])
                VolLabelFlow.connect(FScerebellum, 'output_file',
                                     RemoveCerebellum, 'input_file')
                RemoveCerebellum.inputs.labels_to_remove = \
                    dkt.cerebellum_numbers
                RemoveCerebellum.inputs.output_file = ''
                VolLabelFlow.connect(JoinGrayWhite, 'output_file',
                                     RemoveCerebellum, 'second_file')

    # ========================================================================
    # Split segmented brain into two sides (without medial regions)
    # ========================================================================
    # if modify_surface_labels:
    #     # --------------------------------------------------------------------
    #     # Split brain by masking with left or right labels:
    #     # --------------------------------------------------------------------
    #     SplitBrain = Node(name='Split_brain',
    #                           interface=Fn(function=split_brain,
    #                                        input_names=['image_file',
    #                                                     'label_file',
    #                                                     'left_labels',
    #                                                     'right_labels'],
    #                                        output_names=['left_brain',
    #                                                      'right_brain']))
    #     VolLabelFlow.add_nodes([SplitBrain])
    #     if my_graywhite:
    #         SplitBrain.inputs.image_file = my_graywhite
    #     else:
    #         if use_ants:
    #             if overwrite_cerebrum_with_cerebellum:
    #                 VolLabelFlow.connect(RemoveCerebellum, 'output_file',
    #                                      SplitBrain, 'image_file')
    #             else:
    #                 VolLabelFlow.connect(JoinGrayWhite, 'output_file',
    #                                      SplitBrain, 'image_file')
    #         else:
    #             VolLabelFlow.connect(FSgraywhite, 'output_file',
    #                                  SplitBrain, 'image_file')
    #     if do_input_fs_labels:
    #         mbFlow.connect(labels2nifti, 'labels', VolLabelFlow,
    #                        'Split_brain.label_file')
    #     else:
    #         mbFlow.connect(labelsmgh2nifti, 'output_file', VolLabelFlow,
    #                        'Split_brain.label_file')
    #     SplitBrain.inputs.left_labels = dkt.left_cerebrum_numbers
    #     SplitBrain.inputs.right_labels = dkt.right_cerebrum_numbers

    # ========================================================================
    # Fill cerebrum segmentation volumes with FreeSurfer labels
    #
    # The hybrid segmentation introduces new gray/white matter boundaries,
    # so the corresponding anatomical (gyral/sulcal) boundaries generated by
    # FreeSurfer and ANTs need to be updated accordingly. Mindboggle uses
    # ImageMath's PropagateLabelsThroughMask function in ANTs to propagate
    # anatomical labels to fill the gray and white matter volumes
    # independently. The FreeSurfer-labeled cerebellum voxels overwrite any
    # intersecting cortex voxels.
    # ========================================================================
    # ------------------------------------------------------------------------
    # Extract cerebrum noncortical volume labels:
    # ------------------------------------------------------------------------
    FSnoncortex = Node(name='Extract_freesurfer_noncortex_labels',
                       interface=Fn(function=keep_volume_labels,
                                    input_names=['input_file',
                                                 'labels_to_keep',
                                                 'output_file',
                                                 'second_file'],
                                    output_names=['output_file']))
    VolLabelFlow.add_nodes([FSnoncortex])
    if do_input_fs_labels:
        mbFlow.connect(labels2nifti, 'labels', VolLabelFlow,
                       'Extract_freesurfer_noncortex_labels.input_file')
    else:
        mbFlow.connect(labelsmgh2nifti, 'output_file', VolLabelFlow,
                       'Extract_freesurfer_noncortex_labels.input_file')
    labels_to_fill = dkt.cerebrum_noncortex_numbers + \
                     dkt.brainstem_numbers + \
                     dkt.extra_numbers
    FSnoncortex.inputs.labels_to_keep = labels_to_fill
    FSnoncortex.inputs.output_file = ''
    FSnoncortex.inputs.second_file = ''
    # ------------------------------------------------------------------------
    # Propagate FreeSurfer volume labels through noncortex:
    # ------------------------------------------------------------------------
    FillFSnoncortex = Node(name='Fill_noncortex_with_freesurfer_labels',
                           interface=Fn(function=PropagateLabelsThroughMask,
                                        input_names=['mask',
                                                     'labels',
                                                     'mask_index',
                                                     'output_file',
                                                     'binarize',
                                                     'stopvalue'],
                                        output_names=['output_file']))
    VolLabelFlow.add_nodes([FillFSnoncortex])
    if my_graywhite:
        FillFSnoncortex.inputs.mask = my_graywhite
    else:
        if use_ants:
            if overwrite_cerebrum_with_cerebellum:
                VolLabelFlow.connect(RemoveCerebellum, 'output_file',
                                     FillFSnoncortex, 'mask')
            else:
                VolLabelFlow.connect(JoinGrayWhite, 'output_file',
                                     FillFSnoncortex, 'mask')
        else:
            VolLabelFlow.connect(FSgraywhite, 'output_file',
                                 FillFSnoncortex, 'mask')
    VolLabelFlow.connect(FSnoncortex, 'output_file',
                         FillFSnoncortex, 'labels')
    FillFSnoncortex.inputs.mask_index = 3
    FillFSnoncortex.inputs.output_file = ''
    FillFSnoncortex.inputs.binarize = False
    FillFSnoncortex.inputs.stopvalue = ''
    # ------------------------------------------------------------------------
    # Propagate FreeSurfer surface labels through whole-brain cortex:
    # ------------------------------------------------------------------------
    # if modify_surface_labels:
    #
    #     print('NOTE: Evaluate surface-to-volume label propagation'
    #           ' when surface label modification algorithm complete.')
    #
    #     # --------------------------------------------------------------------
    #     # Propagate surface labels through each hemisphere's cortex:
    #     # --------------------------------------------------------------------
    #     FillcortexFSsurf = Node(
    #                 name='Fill_cortex_with_freesurfer_surface_labels',
    #                 interface=Fn(function=fill_volume_with_surface_labels,
    #                              input_names=['hemi',
    #                                           'left_mask',
    #                                           'right_mask',
    #                                           'surface_files',
    #                                           'mask_index',
    #                                           'output_file',
    #                                           'binarize'],
    #                              output_names=['output_file']))
    #     VolLabelFlow.add_nodes([FillcortexFSsurf])
    #     mbFlow.connect(InputHemis, 'hemi', VolLabelFlow,
    #                    'Fill_cortex_with_freesurfer_surface_labels.hemi')
    #     VolLabelFlow.connect(SplitBrain, 'left_brain',
    #                          FillcortexFSsurf, 'left_mask')
    #     VolLabelFlow.connect(SplitBrain, 'right_brain',
    #                          FillcortexFSsurf, 'right_mask')
    #     mbFlow.connect(SurfLabelFlow, 'Reindex_labels.output_file',
    #         VolLabelFlow,
    #         'Fill_cortex_with_freesurfer_surface_labels.surface_files')
    #     FillcortexFSsurf.inputs.mask_index = 2
    #     FillcortexFSsurf.inputs.output_file = ''
    #     FillcortexFSsurf.inputs.binarize = False
    #     # --------------------------------------------------------------------
    #     # Combine left and right cortical labels:
    #     # --------------------------------------------------------------------
    #     SplitHemiList = JoinNode(name='Split_hemisphere_list',
    #                              interface=Fn(function=split_list_pair,
    #                                           input_names=['List'],
    #                                           output_names=['element1',
    #                                                         'element2']),
    #                              joinsource="Input_hemispheres",
    #                              joinfield="List")
    #     LRcortex = Node(name='Combine_left_right_cortex_labels',
    #                     interface=Fn(function=ImageMath,
    #                                  input_names=['volume1',
    #                                               'volume2',
    #                                               'operator',
    #                                               'output_file'],
    #                                  output_names=['output_file']))
    #     VolLabelFlow.add_nodes([SplitHemiList, LRcortex])
    #     VolLabelFlow.connect(FillcortexFSsurf, 'output_file',
    #                          SplitHemiList, 'List')
    #     VolLabelFlow.connect(SplitHemiList, 'element1', LRcortex, 'volume1')
    #     VolLabelFlow.connect(SplitHemiList, 'element2', LRcortex, 'volume2')
    #     LRcortex.inputs.operator = '+'
    #     LRcortex.inputs.output_file = ''
    #else:
    # ------------------------------------------------------------------------
    # Propagate FreeSurfer volume labels through whole-brain cortex:
    # ------------------------------------------------------------------------
    # Extract FreeSurfer cerebrum cortical volume labels:
    FScortex = FSnoncortex.clone('Extract_freesurfer_cortex_labels')
    VolLabelFlow.add_nodes([FScortex])
    if do_input_fs_labels:
        mbFlow.connect(labels2nifti, 'labels', VolLabelFlow,
                       'Extract_freesurfer_cortex_labels.input_file')
    else:
        mbFlow.connect(labelsmgh2nifti, 'output_file', VolLabelFlow,
                       'Extract_freesurfer_cortex_labels.input_file')
    FScortex.inputs.labels_to_keep = dkt.cerebrum_cortex_numbers
    FScortex.inputs.output_file = ''
    FScortex.inputs.second_file = ''

    # Propagate volume labels through whole-brain cortex:
    FillFScortex = FillFSnoncortex.clone('Fill_cortex_with_freesurfer_labels')
    VolLabelFlow.add_nodes([FillFScortex])
    if my_graywhite:
        FillFScortex.inputs.mask = my_graywhite
    else:
        if use_ants:
            if overwrite_cerebrum_with_cerebellum:
                VolLabelFlow.connect(RemoveCerebellum, 'output_file',
                                     FillFScortex, 'mask')
            else:
                VolLabelFlow.connect(JoinGrayWhite, 'output_file',
                                     FillFScortex, 'mask')
        else:
            VolLabelFlow.connect(FSgraywhite, 'output_file',
                                 FillFScortex, 'mask')
    VolLabelFlow.connect(FScortex, 'output_file',
                         FillFScortex, 'labels')
    FillFScortex.inputs.mask_index = 2
    # ------------------------------------------------------------------------
    # Combine FreeSurfer label-filled whole-brain cortex and noncortex:
    # ------------------------------------------------------------------------
    CombineFSLabels = Node(name=
                           'Combine_freesurfer_cortex_noncortex_labels',
                           interface=Fn(function=overwrite_volume_labels,
                                        input_names=['source',
                                                     'target',
                                                     'output_file',
                                                     'ignore_labels',
                                                     'erase_labels',
                                                     'background_value'],
                                        output_names=['output_file']))
    VolLabelFlow.add_nodes([CombineFSLabels])
    VolLabelFlow.connect(FillFSnoncortex, 'output_file',
                         CombineFSLabels, 'source')
    #if modify_surface_labels:
    #    VolLabelFlow.connect(LRcortex, 'output_file',
    #                         CombineFSLabels, 'target')
    #else:
    VolLabelFlow.connect(FillFScortex, 'output_file',
                         CombineFSLabels, 'target')
    CombineFSLabels.inputs.output_file = ''
    CombineFSLabels.inputs.ignore_labels = [0]
    CombineFSLabels.inputs.erase_labels = False
    CombineFSLabels.inputs.background_value = background_value
    if save_all and not overwrite_cerebrum_with_cerebellum:
        mbFlow.connect(VolLabelFlow,
               'Combine_freesurfer_cortex_noncortex_labels.output_file',
               Sink, 'labels.@freesurfer_filled')

    # ========================================================================
    # Fill whole-brain segmentation volumes with ANTs labels
    #
    # The hybrid segmentation introduces new gray/white matter boundaries,
    # so the corresponding anatomical (gyral/sulcal) boundaries generated by
    # FreeSurfer and ANTs need to be updated accordingly. Mindboggle uses
    # ImageMath's PropagateLabelsThroughMask function in ANTs to propagate
    # anatomical labels to fill the gray and white matter volumes
    # independently. The FreeSurfer-labeled cerebellum voxels overwrite any
    # intersecting cortex voxels.
    # ========================================================================
    if use_ants:
        # --------------------------------------------------------------------
        # Mask brain volume:
        # --------------------------------------------------------------------
        #MaskBrain = Node(name= 'Mask_brain',
        #                 interface=Fn(function=ImageMath,
        #                              input_names=['volume1',
        #                                           'volume2',
        #                                           'operator',
        #                                           'output_file'],
        #                              output_names=['output_file']))
        #VolLabelFlow.add_nodes([MaskBrain])
        #mbFlow.connect(mgh2nifti, 'output_file',
        #               VolLabelFlow, 'Mask_brain.volume1')
        #mbFlow.connect(FetchAnts, 'mask', VolLabelFlow, 'Mask_brain.volume2')
        #MaskBrain.inputs.operator = 'm'
        #MaskBrain.inputs.output_file = ''
        # --------------------------------------------------------------------
        # Transform default atlas labels in MNI152 to subject via template:
        # --------------------------------------------------------------------
        xfm = Node(ApplyTransforms(), name='Apply_ants_transforms')
        VolLabelFlow.add_nodes([xfm])
        xfm.inputs.dimension = 3
        xfm.inputs.default_value = 0
        xfm.inputs.interpolation = 'NearestNeighbor'
        xfm.inputs.invert_transform_flags = warp_inverse_Booleans
        xfm.inputs.output_image = 'ants_labels.nii.gz'
        if my_graywhite:
            xfm.inputs.reference_image = my_graywhite
        else:
            mbFlow.connect(FetchAnts, 'segments', VolLabelFlow,
                           'Apply_ants_transforms.reference_image')
        if my_atlas:
            xfm.inputs.input_image = my_atlas
        else:
            xfm.inputs.input_image = fetch_file_path(atlas_volume)

        mbFlow.connect(ListSubject2mniTransforms, 'string_list', VolLabelFlow,
                       'Apply_ants_transforms.transforms')
        #if save_all:
        #    mbFlow.connect(VolLabelFlow, 'Apply_ants_transforms.output_image',
        #                   Sink, 'labels.@antsRegistration')
        # --------------------------------------------------------------------
        # Extract ANTs cerebral cortical volume labels:
        # --------------------------------------------------------------------
        antsCortex = FSnoncortex.clone('Extract_ants_cortex_labels')
        VolLabelFlow.add_nodes([antsCortex])
        VolLabelFlow.connect(xfm, 'output_image', antsCortex, 'input_file')
        antsCortex.inputs.labels_to_keep = dkt.cerebrum_cortex_numbers
        antsCortex.inputs.output_file = ''
        antsCortex.inputs.second_file = ''
        # --------------------------------------------------------------------
        # Extract ANTs whole-brain noncortical volume labels:
        # --------------------------------------------------------------------
        antsNoncortex = antsCortex.clone('Extract_ants_noncortex_labels')
        VolLabelFlow.add_nodes([antsNoncortex])
        VolLabelFlow.connect(xfm, 'output_image', antsNoncortex, 'input_file')
        antsNoncortex.inputs.labels_to_keep = labels_to_fill
        antsNoncortex.inputs.output_file = ''
        # --------------------------------------------------------------------
        # Propagate ANTs whole-brain cortical volume labels through cortex:
        # --------------------------------------------------------------------
        FillAntsCortex = FillFSnoncortex.clone('Fill_cortex_with_ants_labels')
        VolLabelFlow.add_nodes([FillAntsCortex])
        if my_graywhite:
            FillAntsCortex.inputs.mask = my_graywhite
        else:
            if overwrite_cerebrum_with_cerebellum:
                VolLabelFlow.connect(RemoveCerebellum, 'output_file',
                                     FillAntsCortex, 'mask')
            else:
                VolLabelFlow.connect(JoinGrayWhite, 'output_file',
                                     FillAntsCortex, 'mask')
        VolLabelFlow.connect(antsCortex, 'output_file',
                             FillAntsCortex, 'labels')
        FillAntsCortex.inputs.mask_index = 2
        FillAntsCortex.inputs.output_file = ''
        FillAntsCortex.inputs.binarize = False
        FillAntsCortex.inputs.stopvalue = ''
        # --------------------------------------------------------------------
        # Propagate ANTs whole-brain noncortical labels through noncortex:
        # --------------------------------------------------------------------
        if fill_noncortex_with_ants_labels:
            FillAntsNoncortex = FillAntsCortex.clone(
                'Fill_noncortex_with_ants_labels')
            VolLabelFlow.add_nodes([FillAntsNoncortex])
            if my_graywhite:
                FillAntsNoncortex.inputs.mask = my_graywhite
            else:
                if overwrite_cerebrum_with_cerebellum:
                    VolLabelFlow.connect(RemoveCerebellum, 'output_file',
                                         FillAntsNoncortex, 'mask')
                else:
                    VolLabelFlow.connect(JoinGrayWhite, 'output_file',
                                         FillAntsNoncortex, 'mask')
            VolLabelFlow.connect(antsNoncortex, 'output_file',
                                 FillAntsNoncortex, 'labels')
            FillAntsNoncortex.inputs.mask_index = 3
        # --------------------------------------------------------------------
        # Combine ANTs label-filled cortex and label-filled noncortex:
        # --------------------------------------------------------------------
        CombineAntsLabels = CombineFSLabels.clone(
            'Combine_ants_cortex_noncortex_labels')
        VolLabelFlow.add_nodes([CombineAntsLabels])
        if fill_noncortex_with_ants_labels:
            VolLabelFlow.connect(FillAntsNoncortex, 'output_file',
                                 CombineAntsLabels, 'source')
        else:
            VolLabelFlow.connect(antsNoncortex, 'output_file',
                                 CombineAntsLabels, 'source')
        VolLabelFlow.connect(FillAntsCortex, 'output_file',
                             CombineAntsLabels, 'target')
        CombineAntsLabels.inputs.output_file = ''
        CombineAntsLabels.inputs.ignore_labels = [0]
        CombineAntsLabels.inputs.erase_labels = False
        if save_all and not overwrite_cerebrum_with_cerebellum:
            mbFlow.connect(VolLabelFlow, 
                           'Combine_ants_cortex_noncortex_labels.output_file',
                           Sink, 'labels.@ants_filled')

    # ========================================================================
    # Add FreeSurfer cerebellum labels
    # ========================================================================
    if overwrite_cerebrum_with_cerebellum:
        # --------------------------------------------------------------------
        # ...to FreeSurfer cerebrum labels:
        # --------------------------------------------------------------------
        AddFScerebellum = CombineFSLabels.clone(
            'Add_freesurfer_cerebellum_to_cerebrum')
        VolLabelFlow.add_nodes([AddFScerebellum])
        VolLabelFlow.connect(FScerebellum, 'output_file',
                             AddFScerebellum, 'source')
        VolLabelFlow.connect(CombineFSLabels, 'output_file',
                             AddFScerebellum, 'target')
        AddFScerebellum.inputs.output_file = ''
        AddFScerebellum.inputs.ignore_labels = [0]
        AddFScerebellum.inputs.erase_labels = False
        if save_all:
            mbFlow.connect(VolLabelFlow,
                   'Add_freesurfer_cerebellum_to_cerebrum.output_file',
                    Sink, 'labels.@freesurfer_filled_and_cerebellum')
        # --------------------------------------------------------------------
        # ...to ANTs cerebrum labels:
        # --------------------------------------------------------------------
        if use_ants:
            AddFScerebellum2ANTs = AddFScerebellum.clone(
                'Add_freesurfer_cerebellum_to_ants_cerebrum')
            VolLabelFlow.add_nodes([AddFScerebellum2ANTs])
            VolLabelFlow.connect(FScerebellum, 'output_file',
                                 AddFScerebellum2ANTs, 'source')
            VolLabelFlow.connect(CombineAntsLabels, 'output_file',
                                 AddFScerebellum2ANTs, 'target')
            AddFScerebellum2ANTs.inputs.output_file = ''
            AddFScerebellum2ANTs.inputs.ignore_labels = [0]
            AddFScerebellum2ANTs.inputs.erase_labels = False
            if save_all:
                mbFlow.connect(VolLabelFlow,
                    'Add_freesurfer_cerebellum_to_ants_cerebrum.output_file',
                    Sink, 'labels.@ants_filled_and_cerebellum')

    # ========================================================================
    #
    # Transform labels from added atlas(es) in MNI152 to subject
    #
    # ========================================================================
    if add_atlas_names and use_ants:
        # --------------------------------------------------------------------
        # Find atlas path that contains atlas name:
        # --------------------------------------------------------------------
        MatchAtlas = Node(name='Match_added_atlas',
                      interface=Fn(function=first_string_containing_substring,
                                   input_names=['substring',
                                                'List'],
                                   output_names=['first_matching_string']))
        VolLabelFlow.add_nodes([MatchAtlas])
        mbFlow.connect(InputVolumeAtlases, 'atlas', VolLabelFlow,
                       'Match_added_atlas.substring')
        MatchAtlas.inputs.List = atlases
        # --------------------------------------------------------------------
        # Transform atlas:
        # --------------------------------------------------------------------
        xfm2 = xfm.clone('Transform_added_atlases')
        VolLabelFlow.add_nodes([xfm2])
        xfm2.inputs.output_image = 'ants_added_atlas_labels.nii.gz'
        VolLabelFlow.connect(MatchAtlas, 'first_matching_string',
                             xfm2, 'input_image')
        if my_graywhite:
            xfm2.inputs.reference_image = my_graywhite
        else:
            mbFlow.connect(FetchAnts, 'segments', VolLabelFlow,
                           'Transform_added_atlases.reference_image')
        mbFlow.connect(ListSubject2mniTransforms, 'string_list', VolLabelFlow,
                       'Transform_added_atlases.transforms')
        if save_all:
            mbFlow.connect(VolLabelFlow, 'Transform_added_atlases.output_image',
                           Sink, 'labels.@added_atlases')

    # ========================================================================
    #
    #   Volume feature shapes
    #
    # ========================================================================
    if do_shapes:

        VolShapeFlow = Workflow(name='Volume_feature_shapes')

        # ====================================================================
        # Measure volume of each region of a labeled image file
        #
        # Computing the volume per labeled region is very straightforward:
        # the volume_per_brain_region function simply multiplies the volume
        # per voxel by the number of voxels per region.
        # ====================================================================
        # --------------------------------------------------------------------
        # Volumes of the FreeSurfer labels filling gray/white matter:
        # --------------------------------------------------------------------
        VolumesFSlabels = Node(name='Volume_per_freesurfer_label',
                               interface=Fn(function=volume_per_brain_region,
                                            input_names=['input_file',
                                                         'include_labels',
                                                         'exclude_labels',
                                                         'label_names',
                                                         'save_table',
                                                         'output_table',
                                                         'verbose'],
                                            output_names=['unique_labels',
                                                          'volumes',
                                                          'output_table']))
        VolShapeFlow.add_nodes([VolumesFSlabels])
        VolumesFSlabels.inputs.include_labels = dkt.label_numbers
        VolumesFSlabels.inputs.exclude_labels = []
        VolumesFSlabels.inputs.label_names = dkt.label_names
        VolumesFSlabels.inputs.save_table = True
        VolumesFSlabels.inputs.output_table = \
            'volume_per_freesurfer_label.csv'
        VolumesFSlabels.inputs.verbose = True
        mbFlow.connect(VolLabelFlow,
               'Combine_freesurfer_cortex_noncortex_labels.output_file',
               VolShapeFlow, 'Volume_per_freesurfer_label.input_file')
        mbFlow.connect(VolShapeFlow,
                       'Volume_per_freesurfer_label.output_table',
                       Sink, 'tables.@volumes_of_freesurfer_labels')
        if use_ants:
            # ----------------------------------------------------------------
            # Volumes of the ANTs labels filling gray/white matter:
            # ----------------------------------------------------------------
            VolumesAntsLabels = VolumesFSlabels.clone(
                'Volume_per_ants_label')
            VolShapeFlow.add_nodes([VolumesAntsLabels])
            VolumesAntsLabels.inputs.exclude_labels = [background_value,0]
            VolumesAntsLabels.inputs.output_table = \
                'volume_per_ants_label.csv'
            if overwrite_cerebrum_with_cerebellum:
                mbFlow.connect(VolLabelFlow,
                   'Add_freesurfer_cerebellum_to_ants_cerebrum.output_file',
                   VolShapeFlow, 'Volume_per_ants_label.input_file')
            else:
                mbFlow.connect(VolLabelFlow,
                   'Combine_ants_cortex_noncortex_labels.output_file',
                   VolShapeFlow, 'Volume_per_ants_label.input_file')
            mbFlow.connect(VolShapeFlow,
                           'Volume_per_ants_label.output_table',
                           Sink, 'tables.@volumes_of_ants_labels')
            # ----------------------------------------------------------------
            # Volumes of labels in additional atlases transformed to subject:
            # ----------------------------------------------------------------
            if add_atlas_names:
                VolumesAntsLabels2 = VolumesFSlabels.clone(
                    'Volume_per_added_atlas_label')
                VolShapeFlow.add_nodes([VolumesAntsLabels2])
                VolumesAntsLabels2.inputs.label_names = []
                VolumesAntsLabels2.inputs.include_labels = dkt.label_numbers
                VolumesAntsLabels2.inputs.exclude_labels = [background_value,0]
                VolumesAntsLabels2.inputs.output_table = \
                    'volume_per_added_label.csv'
                mbFlow.connect(VolLabelFlow,
                               'Transform_added_atlases.output_image',
                               VolShapeFlow,
                               'Volume_per_added_atlas_label.input_file')
                # Save table:
                mbFlow.connect(VolShapeFlow,
                               'Volume_per_added_atlas_label.output_table',
                               Sink, 'tables.@volumes_of_added_atlas_labels')

        # ====================================================================
        # Measure volume, thickness of cortical regions of labeled image file
        # ====================================================================
        if do_thickinthehead:
            # ----------------------------------------------------------------
            # Thicknesses of the FreeSurfer cortical labels:
            # ----------------------------------------------------------------
            FSthicknesses = Node(
                name='Thickness_per_freesurfer_cortex_label',
                interface=Fn(function=thickinthehead,
                             input_names=['segmented_file',
                                          'labeled_file',
                                          'cortex_value',
                                          'noncortex_value',
                                          'labels',
                                          'names',
                                          'propagate',
                                          'output_dir',
                                          'save_table',
                                          'output_table',
                                          'verbose'],
                             output_names=['label_volume_thickness',
                                           'output_table']))
            VolShapeFlow.add_nodes([FSthicknesses])
            if my_graywhite:
                FSthicknesses.inputs.segmented_file = my_graywhite
            else:
                if use_ants:
                    if overwrite_cerebrum_with_cerebellum:
                        mbFlow.connect(VolLabelFlow,
                            'Remove_cerebrum_cerebellum_overlap.output_file',
                            VolShapeFlow,
                            'Thickness_per_freesurfer_cortex_label.'
                            'segmented_file')
                    else:
                        mbFlow.connect(VolLabelFlow,
                            'Combine_freesurfer_ants_cerebrum_graywhite.'
                            'output_file',
                            VolShapeFlow,
                            'Thickness_per_freesurfer_cortex_label.'
                            'segmented_file')
                else:
                    mbFlow.connect(VolLabelFlow,
                        'Freesurfer_cerebrum_labels_to_graywhite.output_file',
                        VolShapeFlow,
                        'Thickness_per_freesurfer_cortex_label.'
                        'segmented_file')
            mbFlow.connect(VolLabelFlow,
                'Combine_freesurfer_cortex_noncortex_labels.output_file',
                VolShapeFlow,
                'Thickness_per_freesurfer_cortex_label.labeled_file')
            FSthicknesses.inputs.cortex_value = 2
            FSthicknesses.inputs.noncortex_value = 3
            FSthicknesses.inputs.labels = dkt.cerebrum_cortex_numbers
            FSthicknesses.inputs.names = dkt.cerebrum_cortex_names
            FSthicknesses.inputs.propagate = False
            FSthicknesses.inputs.output_dir = ''
            FSthicknesses.inputs.save_table = True
            FSthicknesses.inputs.output_table = \
                'thickinthehead_per_freesurfer_cortex_label.csv'
            FSthicknesses.inputs.verbose = True
            # Save table:
            mbFlow.connect(VolShapeFlow,
            'Thickness_per_freesurfer_cortex_label.output_table',
            Sink, 'tables.@thicknesses_of_freesurfer_labels')
            # ----------------------------------------------------------------
            # Thicknesses of the ANTs cortical labels:
            # ----------------------------------------------------------------
            if use_ants:
                ANTsThicknesses = FSthicknesses.\
                    clone('Thickness_per_ants_cortex_label')
                VolShapeFlow.add_nodes([ANTsThicknesses])
                if my_graywhite:
                    ANTsThicknesses.inputs.segmented_file = my_graywhite
                else:
                    if overwrite_cerebrum_with_cerebellum:
                        mbFlow.connect(VolLabelFlow,
                            'Remove_cerebrum_cerebellum_overlap.output_file',
                            VolShapeFlow,
                            'Thickness_per_ants_cortex_label.'
                            'segmented_file')
                    else:
                        mbFlow.connect(VolLabelFlow,
                            'Combine_freesurfer_ants_cerebrum_graywhite.'
                            'output_file',
                            VolShapeFlow,
                            'Thickness_per_ants_cortex_label.'
                            'segmented_file')
                if overwrite_cerebrum_with_cerebellum:
                    mbFlow.connect(VolLabelFlow,
                      'Add_freesurfer_cerebellum_to_ants_cerebrum.output_file',
                      VolShapeFlow,
                      'Thickness_per_ants_cortex_label.labeled_file')
                else:
                    mbFlow.connect(VolLabelFlow,
                      'Combine_ants_cortex_noncortex_labels.output_file',
                      VolShapeFlow,
                      'Thickness_per_ants_cortex_label.labeled_file')
                ANTsThicknesses.inputs.labels = dkt.cerebrum_cortex_numbers
                ANTsThicknesses.inputs.names = dkt.cerebrum_cortex_names
                ANTsThicknesses.inputs.output_table = \
                    'thickinthehead_per_ants_cortex_label.csv'
                ANTsThicknesses.inputs.verbose = True
                # Save table:
                mbFlow.connect(VolShapeFlow,
                   'Thickness_per_ants_cortex_label.output_table',
                   Sink, 'tables.@thicknesses_of_ants_filled_cortex_labels')


# ============================================================================
# ----------------------------------------------------------------------------
#
#   Run workflows
#
# ----------------------------------------------------------------------------
# ============================================================================
if __name__ == '__main__':

    from time import time
    time0 = time()

    # ------------------------------------------------------------------------
    # Workflow configuration: content hashing, crashfiles, etc.:
    # ------------------------------------------------------------------------
    mbFlow.config['execution']['hash_method'] = 'content'
    mbFlow.config['execution']['crashfile_format'] = 'txt'
    # Do not propagate the check to sub nodes
    mbFlow.config['execution']['check_version'] = False

    # ------------------------------------------------------------------------
    # Generate a visual graph:
    # ------------------------------------------------------------------------
    graph_vis = args.graph
    if graph_vis:
        if graph_vis == 'exec':
            mbFlow.write_graph(graph2use=graph_vis, simple_form=False)
        else:
            if graph_vis == 'hier':
                graph_vis = 'hierarchical'
            mbFlow.write_graph(graph2use=graph_vis)

    # ------------------------------------------------------------------------
    # Debug: http://nipy.org/nipype/users/config_file.html#debug-configuration
    # ------------------------------------------------------------------------
    debug = False
    if debug:
        config.set('logging', 'workflow_level', 'DEBUG')
        logging.update_logging(config)
        mbFlow.config['execution']['stop_on_first_rerun'] = True
        cpus = 1
    else:
        cpus = args.cpus

    # ------------------------------------------------------------------------
    # Run with or without a plugin:
    # ------------------------------------------------------------------------
    if args.plugin:
        if args.plugin_args:
            mbFlow.run(plugin=args.plugin, plugin_args=eval(args.plugin_args))
        else:
            mbFlow.run(plugin=args.plugin)
    elif cpus > 1:
        mbFlow.run(plugin='MultiProc', plugin_args={'n_procs': cpus})
    else:
        mbFlow.run()

    print('Mindboggle run for {0} complete! ({1:0.2f} seconds)'.
          format(DATA, time() - time0))
